{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:51:49.271749Z",
     "iopub.status.busy": "2025-05-02T21:51:49.271385Z",
     "iopub.status.idle": "2025-05-02T21:51:56.339976Z",
     "shell.execute_reply": "2025-05-02T21:51:56.338964Z",
     "shell.execute_reply.started": "2025-05-02T21:51:49.271712Z"
    },
    "id": "4kO4qZp5ToOI"
   },
   "source": [
    "# Importing Libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import textwrap\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, accuracy_score, median_absolute_error\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import catboost as cb\n",
    "from scipy.optimize import minimize\n",
    "import networkx as nx\n",
    "import time\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import f1_score, accuracy_score, roc_auc_score, roc_curve\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb_available = True\n",
    "except ImportError:\n",
    "    xgb_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:51:56.34131Z",
     "iopub.status.busy": "2025-05-02T21:51:56.341024Z",
     "iopub.status.idle": "2025-05-02T21:52:03.942977Z",
     "shell.execute_reply": "2025-05-02T21:52:03.941759Z",
     "shell.execute_reply.started": "2025-05-02T21:51:56.341281Z"
    },
    "id": "L5dSc61rToOL",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pip install pycirclize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:03.944412Z",
     "iopub.status.busy": "2025-05-02T21:52:03.944041Z",
     "iopub.status.idle": "2025-05-02T21:52:03.949059Z",
     "shell.execute_reply": "2025-05-02T21:52:03.9481Z",
     "shell.execute_reply.started": "2025-05-02T21:52:03.944382Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_type = \"Submission\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "ufDSjPvPToOM"
   },
   "source": [
    "# <span style=\"color:#ffffff; font-size: 1%;\">[1] üß† Introduction</span>\n",
    "\n",
    "<div style=\" border-bottom: 8px solid #E6A600; overflow: hidden; border-radius: 10px; height: 45px; width: 100%; display: flex;\">\n",
    "  <div style=\"height: 100%; width: 65%; background-color: #C2185B; float: left; text-align: center; display: flex; justify-content: center; align-items: center; font-size: 25px; \">\n",
    "    <b><span style=\"color: #ffffff; padding: 20px 20px;\">[1] üß†üéóÔ∏è Introduction</span></b>\n",
    "  </div>\n",
    "  <div style=\"height: 100%; width: 35%; background-image: url('https://www.kaggle.com/competitions/90566/images/header'); background-size: cover; background-position: center; float: left; border-top-right-radius: 10px; border-bottom-right-radius: 4px;\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sirSsyugToON"
   },
   "source": [
    "<div style=\"position: relative; height: 200px; background-image: url('https://cms.buzzrx.com/globalassets/buzzrx/blogs/how-to-manage-adhd-without-medication-for-adults.png'); background-size: cover; background-position: center; border-radius: 15px; overflow: hidden;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GV43HJj1ToON"
   },
   "source": [
    "Neurodevelopmental disorders, such as **Attention Deficit Hyperactivity Disorder (ADHD)**, impact a significant proportion of adolescents, with **approximately 11% diagnosed**‚Äî**14% of boys** and **8% of girls**. However, research suggests that **girls with ADHD are often underdiagnosed**, primarily because their symptoms tend to be more **inattentive rather than hyperactive**, making them harder to detect.\n",
    "\n",
    "This **underdiagnosis has serious consequences**, potentially affecting treatment and outcomes for girls with ADHD.\n",
    "\n",
    "The **WiDS Datathon Kaggle challenge** seeks to address this gap by building **predictive models using functional brain imaging data, socio-demographic details, emotional characteristics, and parenting information** to determine an individual's **ADHD status and biological sex**. Insights from this competition could significantly advance **personalized medicine and targeted interventions for ADHD**, particularly benefiting underrepresented groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_x4DO-sToOO"
   },
   "source": [
    "üìå **Check out my other notebooks**:\n",
    "\n",
    "-  üéôÔ∏è **S5E4**: [ Podcast Pred | EDA & XGB | AI News üåü](https://www.kaggle.com/code/tarundirector/podcast-pred-eda-xgb-ai-news)\n",
    "- üìò **S5E3**: [Rev Rain Prediction | EDA + Time Series + AI News üåßÔ∏è](https://www.kaggle.com/code/tarundirector/rev-rain-pred-eda-time-series-ai-news)  \n",
    "- üéí **S5E2**: [Backpack Prediction | Baseline + Ensemble + EDA üìä](https://www.kaggle.com/code/tarundirector/backpack-pred-baseline-ensemble-eda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nxp58axDToOO"
   },
   "source": [
    "> üí° **Quick Tip**:\n",
    "\"Click on 'Show hidden code' snippets to reveal the code behind the results!\" üëÄüíª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:03.951711Z",
     "iopub.status.busy": "2025-05-02T21:52:03.95141Z",
     "iopub.status.idle": "2025-05-02T21:52:03.967841Z",
     "shell.execute_reply": "2025-05-02T21:52:03.966664Z",
     "shell.execute_reply.started": "2025-05-02T21:52:03.951666Z"
    },
    "id": "uQXo6-s3ToOO",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#üîç Ah-ha! You found the secret sauce! üçî"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emol_cc6ToOO"
   },
   "source": [
    "<div style=\"background-color:  #E8F8F5; border-left: 8px solid #1ABC9C; padding: 20px; border-radius: 8px; font-size: 16px; color: #000000;\">\n",
    "  <h3 style=\"font-size: 16px; margin-bottom: 10px;\"><strong>LOOK OUT FOR -> ü§îüíÅ‚Äç‚ôÄÔ∏èSo What?! :  üîç Insights & Observations</strong></h3>\n",
    "  <p> <em>Insights to understand the analysis and reach meaningful conclusions about the data!</em> üìä</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LtcuDWlToOO"
   },
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\"> <strong>[1.1] üß† Problem Statement</strong></span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRjQq0QCToOP"
   },
   "source": [
    "ADHD diagnosis, particularly in females, remains a challenge due to differences in symptom presentation. Many girls go undiagnosed, leading to long-term mental health impacts. Understanding the **brain activity patterns associated with ADHD** and their **differences between males and females** is crucial for improving early detection and personalized treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fX8f90_ToOP"
   },
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\"> <strong>[1.2] üéØ Goal</strong></span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekR89Xv7ToOP"
   },
   "source": [
    "To develop a predictive model capable of accurately classifying individuals based on:\n",
    "\n",
    "- **ADHD Diagnosis** (`ADHD_Outcome`: 1 for ADHD, 0 for non-ADHD)\n",
    "- **Biological Sex** (`Sex_F` = 1 for Female, 0 for Male)\n",
    "\n",
    "The model will leverage **functional brain imaging data**, along with **socio-demographic details, emotional characteristics, and parenting information**, to identify at-risk individuals more effectively. The ultimate aim is to improve **early diagnosis** and enable **personalised interventions**, thereby reducing negative long-term impacts, especially for females who are traditionally underdiagnosed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ftKMfC8ToOP"
   },
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\"> <strong>[1.3] üóÇ Dataset Description</strong></span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsNYQUiLToOP"
   },
   "source": [
    "The dataset for this competition is derived from multiple sources, primarily from the **Healthy Brain Network (HBN)** and the **Reproducible Brain Charts (RBC) project**, in collaboration with Cornell University and UC Santa Barbara.\n",
    "\n",
    "The dataset contains detailed information on over **1,200+ individuals** in the training set and **300+ individuals** in the test set. The data is divided into two primary folders:\n",
    "\n",
    "#### ‚è© Training Data üèãÔ∏è‚Äç‚ôÇÔ∏è (`train_tsv`)\n",
    "Contains three key components for each subject:\n",
    "1. **Target Variables:** ADHD diagnosis (`ADHD_Outcome`: 0=No, 1=Yes) and biological sex (`Sex_F`: 0=Male, 1=Female).\n",
    "2. **Functional MRI (fMRI) Connectome Matrices:** Time-series data representing **brain activity correlations** across different regions.\n",
    "3. **Socio-Demographic, Emotional, and Parenting Data:** This includes metadata such as **handedness, parental education, emotional health (Strength and Difficulties Questionnaire), and parenting styles (Alabama Parenting Questionnaire)**.\n",
    "   \n",
    "#### ‚è© Test Data üéØ(`test_tsv`)\n",
    "Contains unseen data for **300+ subjects** and consists of:\n",
    "- Functional MRI connectome matrices\n",
    "- Socio-demographic, emotional, and parenting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVVCFfiXToOP"
   },
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\"> <strong>[1.4] üìè Evaluation Metrics</strong></span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-FWE8E3ToOP"
   },
   "source": [
    "### ‚ñ∂Ô∏è **F1 Score - The Core Metric** üî¢\n",
    "The model performance will be evaluated using the **F1 Score**, which is the harmonic mean of **precision** and **recall**:\n",
    "\n",
    "![image.png](https://images.prismic.io/encord/0ef9c82f-2857-446e-918d-5f654b9d9133_Screenshot+%2849%29.png?auto=compress,format)\n",
    "\n",
    "- **Precision**: Measures how many of the predicted positive cases are actually positive.\n",
    "- **Recall**: Measures how many of the actual positive cases are correctly predicted.\n",
    "- **F1 Score**: Balances both precision and recall to give a single metric that reflects model effectiveness.\n",
    "\n",
    "üìå **F1 Score ranges from 0 (worst) to 1 (best), with 1 indicating perfect precision and recall.**\n",
    "\n",
    "### ‚ñ∂Ô∏è **Weighted Scoring for Female ADHD Cases** üèÜ\n",
    "Since the challenge focuses on addressing **gender disparities in ADHD diagnosis**, an additional weighting scheme has been applied:\n",
    "- **Female ADHD cases** (`ADHD_Outcome=1, Sex_F=1`) will receive **2x weight** in the F1 Score calculation.\n",
    "- The final leaderboard score will be based on the **average of the weighted F1 scores** for ADHD and sex prediction.\n",
    "\n",
    "üìå **Why this weighting?** ADHD diagnosis is historically more challenging in females, and the competition aims to highlight and improve **gender-equitable diagnostic models**.\n",
    "\n",
    "For further details on the F1 Score, check out the Wikipedia page: [F1 Score](https://en.wikipedia.org/wiki/F-score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ngjW6-7rToOQ"
   },
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\"> <strong>[1.4] üìè Background</strong></span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RQIYrKUToOQ"
   },
   "source": [
    "### ‚ñ∂Ô∏è Attention Deficit Hyperactivity Disorder (ADHD): Neural and Sex-Specific Patterns\n",
    "\n",
    "**Attention Deficit Hyperactivity Disorder (ADHD)** is a common **neurodevelopmental disorder** that typically emerges in childhood and can persist into adolescence and adulthood. It is characterized by a persistent pattern of **inattention** and/or **hyperactivity-impulsivity** that interferes with an individual's functioning or development.\n",
    "\n",
    "These symptoms may present as:\n",
    "\n",
    "- _Difficulty sustaining attention_\n",
    "- _Being easily distracted or forgetful_\n",
    "- _Excessive fidgeting or restlessness_\n",
    "- _Impulsivity in actions or speech_\n",
    "- _Difficulty waiting one‚Äôs turn_\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ñ∂Ô∏è Brain-Based Differences in ADHD\n",
    "\n",
    "Neuroimaging studies consistently reveal **structural** and **functional differences** in individuals with ADHD compared to controls. Key brain regions implicated include:\n",
    "\n",
    "- **Prefrontal cortex**: essential for _attention_, _executive functions_ (e.g., planning, working memory), and _impulse control_  \n",
    "- **Basal ganglia**: involved in _motor control_, _reward processing_, and _habit formation_\n",
    "- **Cerebellum**: traditionally linked to _motor coordination_, but also supports cognitive functions\n",
    "- **Limbic system**: governs _emotion regulation_\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://miro.medium.com/v2/resize:fit:1100/format:webp/1*1w_w68mfTO5aiePZyOSb6g.jpeg\"\n",
    "    alt=\"ADHD Banner\"\n",
    "    style=\"\n",
    "      display: block;\n",
    "      margin: 0 auto;\n",
    "      border: 2px solid lightgrey;\n",
    "      border-radius: 6px;\n",
    "      padding: 10px;\n",
    "      width: 50%;\n",
    "      height: auto;\n",
    "    \"\n",
    "  />\n",
    "</div>\n",
    "\n",
    "> _Some of these regions ‚Äî including the prefrontal cortex, cerebellum, hippocampus, and amygdala ‚Äî have been found to be slightly smaller in children with ADHD._\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ñ∂Ô∏è Functional Connectivity and Resting-State Insights\n",
    "\n",
    "Functional connectivity studies using **resting-state fMRI (rs-fMRI)** further explore the interaction between brain regions. They have revealed altered connectivity patterns in ADHD, especially in the following networks:\n",
    "\n",
    "- **Default Mode Network (DMN)**: typically active during rest; _hyperconnectivity_ here may contribute to distractibility  \n",
    "- **Executive Control Network (ECN)**: crucial for _goal-directed behavior_  \n",
    "- **Salience Network (SN)**: identifies and filters _important stimuli_\n",
    "\n",
    "These findings indicate that ADHD involves **network-level disruptions**, not just dysfunction in isolated regions.\n",
    "\n",
    "> _Some individuals show hyperconnectivity (e.g., frontal-subcortical), while others exhibit hypoconnectivity (e.g., within the DMN), reflecting ADHD's heterogeneity._\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ñ∂Ô∏è Neurochemical Dimensions\n",
    "\n",
    "ADHD is closely associated with imbalances in **dopamine** and **norepinephrine**, which regulate attention, motivation, and executive functions.\n",
    "\n",
    "- **Dopamine**: central to _reward processing_ and _focus_  \n",
    "- **Norepinephrine**: modulates _alertness_ and _arousal_\n",
    "\n",
    "> _Common ADHD medications like methylphenidate and amphetamines enhance neurotransmitter availability, improving focus and reducing impulsivity._\n",
    "\n",
    "These neurotransmitter shifts may underlie **abnormal connectivity** between brain networks observed in fMRI studies.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ñ∂Ô∏è Sex Differences in ADHD: Why They Matter\n",
    "\n",
    "Understanding how ADHD presents differently across sexes is critical for diagnosis and intervention. While ADHD affects all sexes, it does so in **distinct patterns**:\n",
    "\n",
    "- **Childhood prevalence** is significantly higher in males (_3:1 to 16:1_), but this gap narrows in adulthood.\n",
    "- **Symptom expression**:\n",
    "  - _Males_: externalizing (e.g., hyperactivity, disruptive behavior)\n",
    "  - _Females_: internalizing (e.g., inattention, anxiety, depression)\n",
    "\n",
    "> _This difference contributes to underdiagnosis of ADHD in females, whose symptoms may be subtler and often mistaken for other disorders._\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ñ∂Ô∏è Biological Differences in Connectivity\n",
    "\n",
    "Studies of neurotypical individuals have shown sex-based differences in brain organization:\n",
    "\n",
    "- _Females_: higher **local functional connectivity** and stronger **DMN connectivity**\n",
    "- _Males_: stronger **sensorimotor connectivity**\n",
    "\n",
    "In ADHD-specific studies:\n",
    "\n",
    "- **Female adults with ADHD** showed _reduced connectivity_ in the visual network and its connections to DMN and ECN.\n",
    "- **Male adults with ADHD** displayed altered activity in verbal working memory tasks, unlike females.\n",
    "\n",
    "> _Regions like the **thalamus** and **amygdala** may also exhibit sex-specific alterations in structure and function related to ADHD._\n",
    "\n",
    "These findings underscore the importance of exploring ADHD **through a sex-informed lens**, particularly when building predictive models or designing interventions.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ñ∂Ô∏è Relevance to WiDS Datathon 2025\n",
    "\n",
    "The **WiDS Datathon 2025** provides a unique opportunity to apply these insights on a large dataset of fMRI-derived connectomes. Your task:  \n",
    "- Build **multi-output models** to predict ADHD diagnosis and sex  \n",
    "- Investigate **neurobiological signatures**, especially those that differ across sexes  \n",
    "- Use methods like **Network-Based Statistics (NBS)** or graph metrics to identify key connectivity changes  \n",
    "\n",
    "The goal is not just accuracy ‚Äî it‚Äôs understanding. By decoding sex-specific brain connectivity patterns associated with ADHD, we contribute to more _personalized, fair, and effective_ neuroscience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#ffffff; font-size: 1%;\">[2] üîç Dataset Overview</span>\n",
    "\n",
    "<div style=\" border-bottom: 8px solid #E6A600; overflow: hidden; border-radius: 10px; height: 45px; width: 100%; display: flex;\">\n",
    "  <div style=\"height: 100%; width: 65%; background-color: #C2185B; float: left; text-align: center; display: flex; justify-content: center; align-items: center; font-size: 25px; \">\n",
    "    <b><span style=\"color: #ffffff; padding: 20px 20px;\">[2] üìäüîç Dataset Overview</span></b>\n",
    "  </div>\n",
    "  <div style=\"height: 100%; width: 35%; background-image: url('https://www.kaggle.com/competitions/90566/images/header'); background-size: cover; background-position: center; float: left; border-top-right-radius: 10px; border-bottom-right-radius: 4px;\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:03.969962Z",
     "iopub.status.busy": "2025-05-02T21:52:03.969585Z",
     "iopub.status.idle": "2025-05-02T21:52:28.23391Z",
     "shell.execute_reply": "2025-05-02T21:52:28.232845Z",
     "shell.execute_reply.started": "2025-05-02T21:52:03.969935Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df_cat = pd.read_excel('/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_CATEGORICAL_METADATA_new.xlsx')\n",
    "train_df_fcm= pd.read_csv('/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_FUNCTIONAL_CONNECTOME_MATRICES_new_36P_Pearson.csv')\n",
    "train_df_Q = pd.read_excel('/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAIN_QUANTITATIVE_METADATA_new.xlsx')\n",
    "train_df_sol = pd.read_excel('/kaggle/input/widsdatathon2025/TRAIN_NEW/TRAINING_SOLUTIONS.xlsx')\n",
    "\n",
    "test_df_cat = pd.read_excel('/kaggle/input/widsdatathon2025/TEST/TEST_CATEGORICAL.xlsx')\n",
    "test_df_fcm = pd.read_csv('/kaggle/input/widsdatathon2025/TEST/TEST_FUNCTIONAL_CONNECTOME_MATRICES.csv')\n",
    "test_df_Q = pd.read_excel('/kaggle/input/widsdatathon2025/TEST/TEST_QUANTITATIVE_METADATA.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:28.235129Z",
     "iopub.status.busy": "2025-05-02T21:52:28.234883Z",
     "iopub.status.idle": "2025-05-02T21:52:28.352587Z",
     "shell.execute_reply": "2025-05-02T21:52:28.351721Z",
     "shell.execute_reply.started": "2025-05-02T21:52:28.235108Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_df = pd.read_excel('/kaggle/input/widsdatathon2025/Data Dictionary.xlsx')\n",
    "\n",
    "# Load data\n",
    "dict_APQP_df = pd.read_excel('/kaggle/input/full-data-dictionaries/APQ_P.xlsx', header=None)\n",
    "dict_ColorVision_df = pd.read_excel('/kaggle/input/full-data-dictionaries/ColorVision.xlsx', header=None)\n",
    "dict_SDQ_df = pd.read_excel('/kaggle/input/full-data-dictionaries/SDQ.xlsx', header=None)\n",
    "\n",
    "# Function to get the first value of the second row before setting header\n",
    "def get_first_value_before_header(df, var_name):\n",
    "    first_value = df.iloc[0, 0]  # Second row, first column (before setting header)\n",
    "    print(f\"{var_name}: {first_value}\")\n",
    "\n",
    "# Print first values\n",
    "get_first_value_before_header(dict_APQP_df, \"dict_APQP_df\")\n",
    "get_first_value_before_header(dict_ColorVision_df, \"dict_ColorVision_df\")\n",
    "get_first_value_before_header(dict_SDQ_df, \"dict_SDQ_df\")\n",
    "\n",
    "# Set second row as the header\n",
    "dict_APQP_df.columns = dict_APQP_df.iloc[1]\n",
    "dict_ColorVision_df.columns = dict_ColorVision_df.iloc[1]\n",
    "dict_SDQ_df.columns = dict_SDQ_df.iloc[1]\n",
    "\n",
    "# Drop the first two rows as they are now redundant\n",
    "dict_APQP_df = dict_APQP_df[2:].reset_index(drop=True)\n",
    "dict_ColorVision_df = dict_ColorVision_df[2:].reset_index(drop=True)\n",
    "dict_SDQ_df = dict_SDQ_df[2:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:28.353983Z",
     "iopub.status.busy": "2025-05-02T21:52:28.353609Z",
     "iopub.status.idle": "2025-05-02T21:52:28.382018Z",
     "shell.execute_reply": "2025-05-02T21:52:28.380947Z",
     "shell.execute_reply.started": "2025-05-02T21:52:28.353956Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_df_cat.merge(train_df_Q, on=\"participant_id\", how=\"inner\") \\\n",
    "                        .merge(train_df_sol, on=\"participant_id\", how=\"inner\")\n",
    "\n",
    "test_data = test_df_cat.merge(test_df_Q, on=\"participant_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:28.383537Z",
     "iopub.status.busy": "2025-05-02T21:52:28.383134Z",
     "iopub.status.idle": "2025-05-02T21:52:28.42374Z",
     "shell.execute_reply": "2025-05-02T21:52:28.422478Z",
     "shell.execute_reply.started": "2025-05-02T21:52:28.383484Z"
    },
    "id": "lL9HHJYmToOR"
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:28.42539Z",
     "iopub.status.busy": "2025-05-02T21:52:28.425025Z",
     "iopub.status.idle": "2025-05-02T21:52:28.451359Z",
     "shell.execute_reply": "2025-05-02T21:52:28.450379Z",
     "shell.execute_reply.started": "2025-05-02T21:52:28.425353Z"
    },
    "id": "rJXuzt27ToOR"
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:28.452581Z",
     "iopub.status.busy": "2025-05-02T21:52:28.4523Z",
     "iopub.status.idle": "2025-05-02T21:52:28.469456Z",
     "shell.execute_reply": "2025-05-02T21:52:28.468287Z",
     "shell.execute_reply.started": "2025-05-02T21:52:28.452558Z"
    },
    "id": "KXzbXotDToOS"
   },
   "outputs": [],
   "source": [
    "dict_df['Field'] = dict_df['Field'].replace({'MRI_Track,Age_at_Scan': 'MRI_Track_Age_at_Scan'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:28.470919Z",
     "iopub.status.busy": "2025-05-02T21:52:28.47053Z",
     "iopub.status.idle": "2025-05-02T21:52:28.489212Z",
     "shell.execute_reply": "2025-05-02T21:52:28.488194Z",
     "shell.execute_reply.started": "2025-05-02T21:52:28.470886Z"
    },
    "id": "ndLwXOG3ToOS"
   },
   "outputs": [],
   "source": [
    "# Checking the number of rows and columns\n",
    "\n",
    "num_train_rows, num_train_columns = train_data.shape\n",
    "\n",
    "num_test_rows, num_test_columns = test_data.shape\n",
    "\n",
    "print(\"Training Data:\")\n",
    "print(f\"Number of Rows: {num_train_rows}\")\n",
    "print(f\"Number of Columns: {num_train_columns}\\n\")\n",
    "\n",
    "print(\"Test Data:\")\n",
    "print(f\"Number of Rows: {num_test_rows}\")\n",
    "print(f\"Number of Columns: {num_test_columns}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:28.490739Z",
     "iopub.status.busy": "2025-05-02T21:52:28.490353Z",
     "iopub.status.idle": "2025-05-02T21:52:28.514223Z",
     "shell.execute_reply": "2025-05-02T21:52:28.512798Z",
     "shell.execute_reply.started": "2025-05-02T21:52:28.490699Z"
    },
    "id": "pFlw6zTZToOS"
   },
   "outputs": [],
   "source": [
    "# Count duplicate rows in train_data\n",
    "train_duplicates = train_data.duplicated().sum()\n",
    "\n",
    "# Count duplicate rows in test_data\n",
    "test_duplicates = test_data.duplicated().sum()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of duplicate rows in train_data: {train_duplicates}\")\n",
    "print(f\"Number of duplicate rows in test_data: {test_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:28.5195Z",
     "iopub.status.busy": "2025-05-02T21:52:28.519106Z",
     "iopub.status.idle": "2025-05-02T21:52:28.630595Z",
     "shell.execute_reply": "2025-05-02T21:52:28.62951Z",
     "shell.execute_reply.started": "2025-05-02T21:52:28.519389Z"
    },
    "id": "gejVDLrlToOS"
   },
   "outputs": [],
   "source": [
    "# Creating a table for missing values, unique values and data types of the features\n",
    "\n",
    "missing_values_train = pd.DataFrame({'Feature': train_data.columns,\n",
    "                              '[TRAIN] No. of Missing Values': train_data.isnull().sum().values,\n",
    "                              '[TRAIN] % of Missing Values': ((train_data.isnull().sum().values)/len(train_data)*100)})\n",
    "\n",
    "missing_values_test = pd.DataFrame({'Feature': test_data.columns,\n",
    "                             '[TEST] No.of Missing Values': test_data.isnull().sum().values,\n",
    "                             '[TEST] % of Missing Values': ((test_data.isnull().sum().values)/len(test_data)*100)})\n",
    "\n",
    "unique_values = pd.DataFrame({'Feature': train_data.columns,\n",
    "                              'No. of Unique Values[FROM TRAIN]': train_data.nunique().values})\n",
    "\n",
    "feature_types = pd.DataFrame({'Feature': train_data.columns,\n",
    "                              'DataType': train_data.dtypes})\n",
    "\n",
    "merged_df = pd.merge(missing_values_train, missing_values_test, on='Feature', how='left')\n",
    "merged_df = pd.merge(merged_df, unique_values, on='Feature', how='left')\n",
    "merged_df = pd.merge(merged_df, feature_types, on='Feature', how='left')\n",
    "\n",
    "merged_df.style.background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:28.632882Z",
     "iopub.status.busy": "2025-05-02T21:52:28.632509Z",
     "iopub.status.idle": "2025-05-02T21:52:28.712077Z",
     "shell.execute_reply": "2025-05-02T21:52:28.711047Z",
     "shell.execute_reply.started": "2025-05-02T21:52:28.632852Z"
    },
    "id": "75yU6FhDToOS"
   },
   "outputs": [],
   "source": [
    "# Having a look at the description of all the numerical columns present in the dataset\n",
    "print('Description of all the numerical columns present in the train dataset')\n",
    "train_data.describe().T.style.background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:28.713435Z",
     "iopub.status.busy": "2025-05-02T21:52:28.713164Z",
     "iopub.status.idle": "2025-05-02T21:52:28.778826Z",
     "shell.execute_reply": "2025-05-02T21:52:28.777777Z",
     "shell.execute_reply.started": "2025-05-02T21:52:28.713412Z"
    },
    "id": "I4v7lMvNToOS"
   },
   "outputs": [],
   "source": [
    "# Having a look at the description of all the numerical columns present in the dataset\n",
    "print('Description of all the numerical columns present in the test dataset')\n",
    "test_data.describe().T.style.background_gradient(cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oCfobxJ1ToOT"
   },
   "source": [
    "# <span style=\"color:#ffffff; font-size: 1%;\">[3] üí° Exploratory Data Analysis (EDA)</span>\n",
    "\n",
    "<div style=\" border-bottom: 8px solid #E6A600; overflow: hidden; border-radius: 10px; height: 45px; width: 100%; display: flex;\">\n",
    "  <div style=\"height: 100%; width: 65%; background-color: #C2185B; float: left; text-align: center; display: flex; justify-content: center; align-items: center; font-size: 25px; \">\n",
    "    <b><span style=\"color: #ffffff; padding: 20px 20px;\">[3] üìàüí°EDA</span></b>\n",
    "  </div>\n",
    "  <div style=\"height: 100%; width: 35%; background-image: url('https://www.kaggle.com/competitions/90566/images/header'); background-size: cover; background-position: center; float: left; border-top-right-radius: 10px; border-bottom-right-radius: 4px;\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:28.780401Z",
     "iopub.status.busy": "2025-05-02T21:52:28.780027Z",
     "iopub.status.idle": "2025-05-02T21:52:28.78505Z",
     "shell.execute_reply": "2025-05-02T21:52:28.784133Z",
     "shell.execute_reply.started": "2025-05-02T21:52:28.780367Z"
    },
    "id": "U-cN0wjtToOT"
   },
   "outputs": [],
   "source": [
    "categorical_variables = ['Basic_Demos_Enroll_Year', 'Basic_Demos_Study_Site', 'PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race',\n",
    "'MRI_Track_Scan_Location', 'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ',\n",
    "'ColorVision_CV_Score', 'APQ_P_APQ_P_CP', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Generating_Impact',\n",
    "'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial']\n",
    "\n",
    "numerical_variables = ['EHQ_EHQ_Total', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM',\n",
    "'APQ_P_APQ_P_PP', 'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Internalizing', 'MRI_Track_Age_at_Scan']\n",
    "\n",
    "target_variables = ['ADHD_Outcome', 'Sex_F']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5P9aZN7ToOT"
   },
   "source": [
    "> **‚ö†Ô∏è NOTE:** Some features that appear as **numerical** in the dataset are actually more **categorical in nature** (since they have very few unique values). We‚Äôll treat them accordingly to ensure meaningful insights!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0_Sc2FQ3ToOT"
   },
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\"> <strong>[3.1] Numerical Feature Analysis (Univariate Analysis - Survey Data)</strong></span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:28.786514Z",
     "iopub.status.busy": "2025-05-02T21:52:28.786154Z",
     "iopub.status.idle": "2025-05-02T21:52:43.662843Z",
     "shell.execute_reply": "2025-05-02T21:52:43.661771Z",
     "shell.execute_reply.started": "2025-05-02T21:52:28.786466Z"
    },
    "id": "Pb_QyTPQToOT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "# Define custom color palettes\n",
    "box_palette = {'Train': '#F46D43', 'Test': '#66C2A5'}   # Dark green for Train, red for Test\n",
    "hist_train_color = '#F46D43'  # Darkish green for Train histogram\n",
    "hist_test_color = '#66C2A5'   # Use same color as before for Test histogram\n",
    "\n",
    "# Palettes for the additional KDE plots\n",
    "gender_palette = {\"Male\": \"lightblue\", \"Female\": \"lightpink\"}\n",
    "adhd_palette = {\"Non-ADHD\": \"grey\", \"ADHD\": \"#FFDB58\"}\n",
    "\n",
    "# Add 'Dataset' column to distinguish between train and test data\n",
    "train_data['Dataset'] = 'Train'\n",
    "test_data['Dataset'] = 'Test'\n",
    "\n",
    "# Ensure we only analyze the numerical variables\n",
    "variables = [col for col in train_data.columns if col in numerical_variables]\n",
    "\n",
    "# Create new columns for gender and ADHD status if not already present.\n",
    "# Assuming train_data has a binary \"Sex_F\" column where 1 represents Female.\n",
    "if 'Gender' not in train_data.columns:\n",
    "    train_data['Gender'] = train_data['Sex_F'].apply(lambda x: \"Female\" if x == 1 else \"Male\")\n",
    "\n",
    "# Assuming \"ADHD_Outcome\" is binary with 1 meaning ADHD and 0 meaning Non-ADHD.\n",
    "if 'ADHD_Status' not in train_data.columns:\n",
    "    train_data['ADHD_Status'] = train_data['ADHD_Outcome'].apply(lambda x: \"ADHD\" if x == 1 else \"Non-ADHD\")\n",
    "\n",
    "# Function to create and display a row of plots for a single variable\n",
    "def create_variable_plots(variable):\n",
    "    sns.set_style('whitegrid')\n",
    "\n",
    "    # Create a 1x4 subplot: box plot, histogram, gender KDE, ADHD KDE\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(24, 5))\n",
    "\n",
    "    # ---------------------\n",
    "    # 1. Box plot (Train & Test Combined)\n",
    "    # ---------------------\n",
    "    combined_data = pd.concat([train_data, test_data])\n",
    "    sns.boxplot(ax=axes[0], data=combined_data, x=variable, y=\"Dataset\", palette=box_palette)\n",
    "    axes[0].set_xlabel(variable)\n",
    "    title_box = f\"Box Plot for {dict_df.loc[dict_df['Field'] == variable, 'Description'].values[0]}  [TRAIN & TEST Combined]\"\n",
    "    axes[0].set_title(\"\\n\".join(textwrap.wrap(title_box, width=50)))\n",
    "\n",
    "    # ---------------------\n",
    "    # 2. Histogram (Countplot) for Train vs Test\n",
    "    # ---------------------\n",
    "    sns.histplot(ax=axes[1], data=train_data, x=variable, color=hist_train_color, kde=True, bins=30, label=\"Train\")\n",
    "    sns.histplot(ax=axes[1], data=test_data, x=variable, color=hist_test_color, kde=True, bins=30, label=\"Test\")\n",
    "    axes[1].set_xlabel(variable)\n",
    "    axes[1].set_ylabel(\"Frequency\")\n",
    "    title_hist = f\"Histogram for {variable}:  {dict_df.loc[dict_df['Field'] == variable, 'Description'].values[0]} [TRAIN & TEST]\"\n",
    "    axes[1].set_title(\"\\n\".join(textwrap.wrap(title_hist, width=50)))\n",
    "    axes[1].legend()\n",
    "\n",
    "    # ---------------------\n",
    "    # 3. KDE Plot by Gender (Male vs Female)\n",
    "    # ---------------------\n",
    "    sns.kdeplot(ax=axes[2], data=train_data, x=variable, hue=\"Gender\", fill=True, common_norm=False,\n",
    "                palette=gender_palette, alpha=0.4, linewidth=2)\n",
    "    axes[2].set_xlabel(variable)\n",
    "    axes[2].set_title(f\"KDE by Gender for {variable}\")\n",
    "\n",
    "    # ---------------------\n",
    "    # 4. KDE Plot by ADHD Status (ADHD vs Non-ADHD)\n",
    "    # ---------------------\n",
    "    sns.kdeplot(ax=axes[3], data=train_data, x=variable, hue=\"ADHD_Status\", fill=True, common_norm=False,\n",
    "                palette=adhd_palette, alpha=0.4, linewidth=2)\n",
    "    axes[3].set_xlabel(variable)\n",
    "    axes[3].set_title(f\"KDE by ADHD Status for {variable}\")\n",
    "\n",
    "    # Adjust spacing and show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Perform univariate analysis for each variable in the list\n",
    "for variable in variables:\n",
    "    create_variable_plots(variable)\n",
    "\n",
    "# Clean up: Drop the 'Dataset' column after analysis if desired\n",
    "train_data.drop('Dataset', axis=1, inplace=True)\n",
    "test_data.drop('Dataset', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#ffffff; font-size: 1%;\">SW-Key-Features-Insights</span>\n",
    "<div style=\"background-color:#E8F8F5; border-left:8px solid #1ABC9C; padding:20px; border-radius:8px; font-size:14px; color:#000000;\">\n",
    "  <h3 style=\"font-size:20px; margin-bottom:10px;\">ü§îüíÅ‚Äç‚ôÄÔ∏èSo What?! <strong>(üìù Key Insights - Summary)</strong></h3>\n",
    "  <hr>\n",
    "  <ul>\n",
    "    <li><strong><code>SDQ Difficulties</code> &amp; <code>Externalizing</code>:</strong> These scores show marked differences between <code>ADHD</code> and <code>non-ADHD</code> subjects‚Äîwith <code>ADHD</code> cases scoring significantly higher. This highlights their crucial role in flagging behavioral challenges.</li>\n",
    "    <li><strong><code>Positive Parenting</code>:</strong> The bimodal trend observed for <code>males</code> (and similarly for <code>ADHD</code> subjects) hints at distinct parenting subgroups, which is key to understanding different outcomes in the sample.</li>\n",
    "    <li><strong><code>Parental Involvement</code>:</strong> Slight shifts in peak scores between <code>males</code> and <code>females</code>, as well as between <code>ADHD</code> and <code>non-ADHD</code> groups, suggest that variations in parental engagement may influence behavioral profiles.</li>\n",
    "    <li><strong><code>Age at MRI Scan</code>:</strong> The <code>Age at MRI Scan</code> is normally distributed with overlapping peaks, confirming that age is well-controlled and not a confounding factor.</li>\n",
    "  </ul>\n",
    "\n",
    "  <h3 style=\"font-size:20px; margin-bottom:10px;\">ü§îüíÅ‚Äç‚ôÄÔ∏èSo What?! <strong>(üìù Key Insights - Detailed)</strong></h3>\n",
    "  <hr>\n",
    "  <p><strong>1Ô∏è‚É£ Handedness Measure <code>(ehq_ehq_total)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> The distribution is left-skewed with a long tail, peaking around 90 for both <code>males</code> and <code>females</code>, with a slightly lower peak for <code>non-ADHD</code> subjects.</li>\n",
    "    <li><strong>Interpretation:</strong> Derived from the Edinburgh Handedness Questionnaire, this score quantifies the <code>Laterality Index</code>‚Äîwith the data dictionary indicating a scale from <code>-100</code> (extreme left-hand dominance) to <code>100</code> (extreme right-hand dominance). The observed peak around 90 suggests that most participants exhibit a strong right-hand preference. The near-identical distribution for both sexes implies similar lateralization; however, the marginally lower peak in <code>non-ADHD</code> subjects may indicate that <code>ADHD</code> individuals possess an even stronger lateralization tendency, potentially reflecting subtle neurodevelopmental differences.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "  <p><strong>2Ô∏è‚É£ Inconsistent Discipline Score <code>(apq_p_apq_p_id)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> This score is normally distributed with a prominent peak around <code>14</code>, showing substantial overlap between <code>males</code> and <code>females</code> as well as between <code>ADHD</code> and <code>non-ADHD</code> groups.</li>\n",
    "    <li><strong>Interpretation:</strong> As a measure from the Alabama Parenting Questionnaire, this score reflects <code>inconsistencies in parental discipline</code>. Considering that the APQ response options range from 1 (Never) to 5 (Always) per item, a composite score peaking around <code>14</code> suggests that most parents exhibit moderate inconsistency. The uniform distribution across groups indicates that inconsistent discipline is a common practice, offering limited differentiation between <code>sexes</code> or diagnostic categories.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "  <p><strong>3Ô∏è‚É£ Parental Involvement Score <code>(apqp_apq_p_inv)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> The score follows a normal distribution, with <code>males</code> peaking around <code>42</code> and <code>females</code> around <code>38</code>; similarly, <code>non-ADHD</code> subjects peak around <code>42</code> while <code>ADHD</code> subjects peak near <code>38</code>.</li>\n",
    "    <li><strong>Interpretation:</strong> This variable captures <code>parental involvement</code>‚Äîa higher score reflects greater engagement. Although the exact scale isn‚Äôt provided, given the APQ items (rated 1‚Äì5), a sum score in the high 30s to low 40s indicates moderate to high involvement. The observed shift‚Äîwith higher scores in <code>males</code> and <code>non-ADHD</code> subjects‚Äîsuggests that increased parental involvement may be protective against <code>ADHD</code> and may also vary by <code>sex</code>, thereby affecting behavioral outcomes.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "  <p><strong>4Ô∏è‚É£ Other Discipline Practices <code>(apq_p_apq_opd)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> The distribution is normal with peaks between <code>17</code> and <code>18</code>, and a subtle trend where <code>non-ADHD</code> subjects score slightly lower.</li>\n",
    "    <li><strong>Interpretation:</strong> This score assesses <code>alternative disciplinary methods</code> beyond those contributing to the overall discipline score. With response options from 1 to 5 per item, a summed score of around <code>17‚Äì18</code> implies a moderate frequency of these practices. The slight decrease in <code>non-ADHD</code> subjects may suggest that such methods are more frequently employed with children exhibiting <code>ADHD</code>-related behaviors, potentially contributing to the diagnostic differentiation.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "  <p><strong>5Ô∏è‚É£ Poor Monitoring/Supervision Score <code>(apq_p_apq_pm)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Exhibits a slight right skew with a peak around <code>15</code> and almost complete overlap between all groups.</li>\n",
    "    <li><strong>Interpretation:</strong> This metric measures <code>monitoring and supervision</code> practices. A right-skewed pattern indicates that while most parents maintain adequate supervision, a subset demonstrates poorer practices (reflected in higher scores). Given the similar distributions for both <code>males</code> and <code>females</code> as well as between <code>ADHD</code> and <code>non-ADHD</code> groups, it suggests that monitoring is relatively consistent across the board and may not be a key differentiator in behavioral outcomes.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "  <p><strong>6Ô∏è‚É£ Positive Parenting Score <code>(apq_p_apq_p_pp)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> This variable shows a bimodal distribution; <code>males</code> display two distinct peaks (approximately <code>25</code> and <code>28</code>), while <code>females</code> have a single, slightly left-skewed peak around <code>28</code>. In the <code>ADHD</code> context, <code>ADHD</code> subjects exhibit dual peaks at roughly <code>24</code> and <code>28</code>, whereas <code>non-ADHD</code> subjects cluster near <code>27</code>.</li>\n",
    "    <li><strong>Interpretation:</strong> The <code>Positive Parenting Score</code>, reflecting affirmative and supportive behaviors, is derived from multiple items (each rated 1‚Äì5). A composite score in the mid-to-high 20s indicates generally positive reinforcement. The bimodal distribution for <code>males</code> and <code>ADHD</code> subjects may indicate two subgroups: one with consistently high positive parenting and another with moderate levels. In contrast, the more uniform score for <code>females</code> and <code>non-ADHD</code> subjects suggests a more homogeneous parenting approach. These distinctions are pivotal in understanding how positive reinforcement may influence the behavioral profiles of different groups.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "  <p><strong>7Ô∏è‚É£ Overall Behavioral Difficulties <code>(sdq_sdq_difficulties_total)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> <code>males</code> exhibit a broad peak around <code>10</code>, whereas <code>females</code> show two peaks (around <code>8</code> and <code>14</code>). In the <code>ADHD</code> context, there is a stark contrast: <code>ADHD</code> subjects peak near <code>14</code>, while <code>non-ADHD</code> subjects cluster around <code>5</code>.</li>\n",
    "    <li><strong>Interpretation:</strong> This metric, summarizing overall behavioral and emotional challenges from the Strength and Difficulties Questionnaire (which typically ranges from 0 to 40), reveals that scores around <code>14</code> indicate heightened difficulties. The pronounced difference between <code>ADHD</code> (peaking at <code>14</code>) and <code>non-ADHD</code> (peaking at <code>5</code>) subjects underscores its strong discriminative power. For <code>females</code>, the dual peaks may reflect the existence of subgroups with varying severity, while the broad peak for <code>males</code> suggests a wider spread of difficulties. This clear divergence directs attention to the importance of elevated difficulty scores as a key indicator of <code>ADHD</code>.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "  <p><strong>8Ô∏è‚É£ Externalizing Behaviors <code>(sdq_sdq_externalizing)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> The distribution is normal with a <code>male</code> peak around <code>8</code> and a <code>female</code> peak around <code>5</code>. In <code>ADHD</code> subjects, the peak is near <code>8</code>, while <code>non-ADHD</code> subjects exhibit a right-skewed trend with a peak around <code>2</code>.</li>\n",
    "    <li><strong>Interpretation:</strong> Measuring behaviors such as hyperactivity and aggression, the <code>Externalizing</code> score (often ranging from 0 to 10) is significantly higher in <code>males</code> and in <code>ADHD</code> subjects. The concentrated peak at <code>8</code> for these groups contrasts with the much lower scores in <code>non-ADHD</code> subjects, emphasizing its value in highlighting disruptive behaviors that may require targeted interventions.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "  <p><strong>9Ô∏è‚É£ Internalizing Behaviors <code>(sdq_sdq_internalizing)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Both <code>males</code> and <code>females</code> display a right-skewed distribution with overlapping peaks around <code>2‚Äì3</code>. However, <code>ADHD</code> subjects show a broader, more diffuse peak around <code>3</code>, while <code>non-ADHD</code> subjects have a taller, sharper peak near <code>1</code>.</li>\n",
    "    <li><strong>Interpretation:</strong> This score reflects <code>internalizing behaviors</code> (e.g., anxiety, depression) and typically has lower values. The broader distribution for <code>ADHD</code> subjects implies higher variability and intensity of these symptoms, suggesting that children with <code>ADHD</code> experience a wider range of emotional challenges. In contrast, the concentrated peak at <code>1</code> among <code>non-ADHD</code> subjects indicates more stable emotional well-being, reinforcing the contrast in behavioral profiles between the groups.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "  <p><strong>üîü Age at MRI Scan <code>(mri_track_age_at_scan)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> The distribution is normal with overlapping peaks around <code>10</code> years of age.</li>\n",
    "    <li><strong>Interpretation:</strong> This variable records the <code>age</code> of participants at the time of their MRI scan. Its consistent distribution‚Äîsupported by a narrow range around <code>10</code> years‚Äîconfirms that age is well-controlled across the sample. This uniformity allows us to confidently attribute observed differences in behavioral and parental factors to true variations in the subjects rather than to developmental differences.</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uk42cooWToOU"
   },
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\"> <strong>[3.2] Numerical Feature Analysis (Connectome Data)</strong></span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5An9A-_hToOU"
   },
   "source": [
    "### [3.2.1] üü° **Background**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_O9BRiPMToOU"
   },
   "source": [
    "### ‚ñ∂Ô∏è **Fundamentals of Functional Magnetic Resonance Imaging (fMRI): Peering into Brain Activity**\n",
    "\n",
    "fMRI is a neuroimaging technique that allows researchers to observe brain activity in a **non-invasive** manner. It works by detecting changes in blood flow and blood oxygenation in response to neural activity‚Äîa phenomenon known as the **Blood-Oxygen-Level-Dependent (BOLD) signal**.\n",
    "\n",
    "‚è© **BOLD Signal Mechanism:**\n",
    "- When a brain area becomes more active, it consumes more oxygen.\n",
    "- To compensate, **blood flow increases** to that region, often resulting in a local oversupply of oxygenated blood.\n",
    "- fMRI does not measure neural activity directly; instead, it detects the **hemodynamic response** (i.e., the changes in blood flow and oxygenation).\n",
    "\n",
    "‚è© **Magnetic Properties and fMRI:**\n",
    "- **Deoxygenated hemoglobin** is _paramagnetic_ (attracted to magnetic fields and causing local distortions).\n",
    "- **Oxygenated hemoglobin** is _diamagnetic_ and has a much weaker effect on the magnetic field.\n",
    "- The **influx of oxygenated blood** decreases the concentration of deoxygenated hemoglobin, creating a more uniform magnetic environment detectable by the MRI scanner.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ñ∂Ô∏è **Constructing and Understanding the fMRI Connectivity Matrix: Mapping Functional Relationships**\n",
    "\n",
    "\n",
    "<div style=\"text-align: center;\">\n",
    "  <img\n",
    "    src=\"https://media-hosting.imagekit.io/39652e926f4a4c58/WIDS1.png?Expires=1838310357&Key-Pair-Id=K2ZIVPTIP2VGHC&Signature=P4SfWRRV3okuqA7d-mtQe0BTQn9116Ml2GEF5IhqAXbJr9N1ImOCXZg-IDAz4QqxbeuiYsvsEbxCtmYgKIkRYvFsx6TDxp8JGRwYjKh5LvUOFyM3FGd669BDJbmzvLP4GVYiwuTWlJXgpJkmYryZOOt4Fn0dU-A1JVXxhWiFoh9u74Su6eN44blEqWkiZ1~ooZHmx3Gp2Gm11miAMVQ8TDz5LhNpHofXyM3ZOrCqN3U7u0HBdv8ROybFRrdhp1Az9qC0Xs4VBjDqgTqiEljH1loKXVDyjXERNCE47Apdn2tGP8lbHDg8~XbGQsxFJYtcE3fprFynElPgrNsEzcMf7A__\"\n",
    "    alt=\"ADHD Banner\"\n",
    "    style=\"\n",
    "      display: block;\n",
    "      margin: 0 auto;\n",
    "      border: 2px solid lightgrey;\n",
    "      border-radius: 6px;\n",
    "      padding: 10px;\n",
    "      width: 75%;\n",
    "      height: auto;\n",
    "    \"\n",
    "  />\n",
    "</div>\n",
    "\n",
    "\n",
    "To transform raw fMRI data into a functional connectome:\n",
    "\n",
    "‚è© **Parcellation:**\n",
    "- The brain is first divided into a set of distinct regions or _nodes_.\n",
    "- This can be achieved using:\n",
    "  - **Anatomical atlases** (regions defined by structural boundaries)\n",
    "  - **Functional parcellation techniques** (grouping voxels based on similarity in BOLD signal time series)\n",
    "\n",
    "‚è© **Quantifying Relationships:**\n",
    "- The next step is to quantify the statistical relationship between the BOLD signal time series of each pair of regions.\n",
    "- The **Pearson correlation coefficient** is most commonly used:\n",
    "  - Measures the strength and direction of the linear relationship between two time series.\n",
    "  - Ranges from **-1** (perfect negative correlation) to **+1** (perfect positive correlation), with **0** indicating no linear correlation.\n",
    "- Other measures (e.g., covariance, mutual information) can also assess these relationships.\n",
    "\n",
    "‚è© **The Connectivity Matrix:**\n",
    "- The result is a connectivity (or correlation) matrix, where:\n",
    "  - Each element *(i, j)* represents the strength of the functional connection between brain region *i* and *j*.\n",
    "  - For **N** brain regions, the matrix is of size **N x N**.\n",
    "  - The matrix is **symmetric** because the correlation between *i* and *j* is the same as between *j* and *i*.\n",
    "  - Diagonal elements are typically **1** (correlation of a region with itself).\n",
    "\n",
    "‚è© **Interpreting the Matrix:**\n",
    "- **High positive correlation:** Suggests that the two regions have synchronous fluctuations, implying they may be involved in similar or interacting processes.\n",
    "- **Correlation near zero:** Indicates little or no linear relationship.\n",
    "- **Negative correlation:** Suggests anti-correlation; when one region's activity increases, the other decreases.\n",
    "- Importantly, the connectivity matrix reflects statistical relationships and does **not imply causality**.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ñ∂Ô∏è **Vectorized Connectivity Data for the Competition**\n",
    "\n",
    "The provided dataset (`train_df_fcm.columns`) is in a vectorized form of this connectivity matrix:\n",
    "\n",
    "‚è© **Key Details:**\n",
    "- The vectorized form contains the unique information from the upper (or lower) triangle of the matrix (excluding the diagonal).\n",
    "- Given that there are **19900** connectivity columns (excluding `participant_id`), this represents:\n",
    "  \n",
    "  ‚è© **Calculation:**  \n",
    "  $$\n",
    "    \\frac{N \\times (N - 1)}{2} = 19900\n",
    "    $$\n",
    "  \n",
    "  Solving for **N** gives **N = 200**.\n",
    "\n",
    "- Therefore, the data represents the functional connectivity between **200 brain regions**.\n",
    "\n",
    "‚è© **Processing Steps:**\n",
    "- The vectorized matrix should be reshaped back into its original **200 x 200 symmetric matrix**.\n",
    "- **Preprocessing options** include:\n",
    "  - **Normalization:** Scaling the correlation values to a specific range (e.g., -1 to 1).\n",
    "  - **Thresholding:** Setting weak or statistically non-significant connections to zero.\n",
    "  - **Averaging:** If multiple connectivity matrices exist per participant (e.g., from different scans), they may be averaged for reliability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NA8WOYM_ToOU"
   },
   "source": [
    "<hr style=\"height:3px; background-color:black; border:none;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0CjvYzkToOU"
   },
   "source": [
    "### [3.2.2] üü° **Visualizations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s04FGIloToOV"
   },
   "source": [
    "### ‚Ü™Ô∏è [3.2.2.1] **Feature Extraction from Connectome Data: Unlocking Predictive Power**\n",
    "\n",
    "To leverage the information contained within **_connectome data_** for predictive tasks‚Äîsuch as identifying individuals with **_ADHD_** or estimating their age‚Äîit is essential to extract meaningful features that capture the underlying organization and properties of the brain network. **_Graph theory_** offers a powerful framework for this purpose, providing a rich set of metrics to quantify various aspects of brain network organization.\n",
    "\n",
    "These metrics can be broadly categorized into:\n",
    "- **_Nodal measures_** ‚Äì describe the properties of individual brain regions (nodes).\n",
    "- **_Global measures_** ‚Äì characterize the network as a whole.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚è© **Nodal Measures**\n",
    "These provide insights into the role and characteristics of individual brain regions within the network:\n",
    "\n",
    "- **_Degree_**  \n",
    "  ‚Üí Counts the number of connections a node has.  \n",
    "  ‚Üí In the brain, regions with a **high degree** may act as **central hubs**, interacting with many other regions.\n",
    "\n",
    "- **_Strength_**  \n",
    "  ‚Üí Sum of the weights of all connections associated with a node.  \n",
    "  ‚Üí In **functional connectivity networks**, it reflects the **overall level of correlated activity** between a brain region and the rest of the brain.\n",
    "\n",
    "- **_Centrality Measures_** (e.g., **_Betweenness Centrality_**)  \n",
    "  ‚Üí Assess how **important** a node is in the network‚Äôs communication pathways.  \n",
    "  ‚Üí **Betweenness centrality** quantifies how often a node lies on the **shortest path** between any two other nodes.  \n",
    "  ‚Üí High betweenness regions may act as **critical bridges** for information flow.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚è© **Global Measures**\n",
    "These provide an overall characterization of the brain network‚Äôs architecture:\n",
    "\n",
    "- **_Clustering Coefficient_**  \n",
    "  ‚Üí Measures how interconnected a node‚Äôs neighbors are.  \n",
    "  ‚Üí High values indicate **tightly linked local circuits**, suggesting **specialized processing modules**.\n",
    "\n",
    "- **_Characteristic Path Length_**  \n",
    "  ‚Üí Average of the shortest path lengths between all pairs of nodes.  \n",
    "  ‚Üí Reflects **global integration** or **efficiency** of information transfer across the network.  \n",
    "  ‚Üí Shorter path lengths imply **more efficient communication**.\n",
    "\n",
    "- **_Global Efficiency_**  \n",
    "  ‚Üí Average of the **inverse shortest path lengths** between all node pairs.  \n",
    "  ‚Üí Quantifies **how well information is exchanged** across the entire network.\n",
    "\n",
    "- **_Modularity_**  \n",
    "  ‚Üí Measures the degree to which a network can be split into **distinct communities** or **modules**.  \n",
    "  ‚Üí High modularity implies **specialized functional units** in the brain.\n",
    "\n",
    "- **_Small-Worldness_**  \n",
    "  ‚Üí A property combining **high clustering** (like a regular network) and **short path lengths** (like a random network).  \n",
    "  ‚Üí Represents an optimal balance between **segregation** and **integration**, considered ideal for brain networks.\n",
    "\n",
    "Each measure captures a **distinct aspect** of network organization, with **varying relevance** depending on the biological phenomenon being studied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:52:43.664437Z",
     "iopub.status.busy": "2025-05-02T21:52:43.664126Z",
     "iopub.status.idle": "2025-05-02T21:53:03.224288Z",
     "shell.execute_reply": "2025-05-02T21:53:03.22324Z",
     "shell.execute_reply.started": "2025-05-02T21:52:43.66441Z"
    },
    "id": "WB2vCt4sToOV",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# -----------------------\n",
    "# Merge Features with Solutions\n",
    "# -----------------------\n",
    "train_features_df = pd.read_csv('/kaggle/input/full-data-dictionaries/train_connectome_features.csv')\n",
    "train_merged = pd.merge(train_features_df, train_df_sol, on='participant_id')\n",
    "\n",
    "# -----------------------\n",
    "# Define Colors for ADHD and Sex outcomes\n",
    "# -----------------------\n",
    "# For ADHD: 0 = grey, 1 = yellow\n",
    "adhd_colors = {0: '#808080', 1: '#f1c40f'}\n",
    "# For Sex: 0 = blue (male), 1 = pink (female)\n",
    "sex_colors = {0: '#3498db', 1: '#e91e63'}\n",
    "\n",
    "# -----------------------\n",
    "# Define List of Feature Columns to Plot\n",
    "# -----------------------\n",
    "plot_columns = [\n",
    "    'mean_degree', 'std_degree', 'mean_strength', 'std_strength',\n",
    "    'mean_betweenness', 'std_betweenness', 'avg_clustering',\n",
    "    'characteristic_path_length', 'global_efficiency', 'modularity',\n",
    "    'small_worldness', 'num_connected_components'\n",
    "]\n",
    "\n",
    "# -----------------------\n",
    "# Plotting Loop: For each feature, create 4 subplots (2x2)\n",
    "# -----------------------\n",
    "for col in plot_columns:\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(20, 12))\n",
    "\n",
    "    # Use participant_id as x-axis if numeric; otherwise, use the index.\n",
    "    if pd.api.types.is_numeric_dtype(train_merged['participant_id']):\n",
    "        x_vals = train_merged['participant_id']\n",
    "    else:\n",
    "        x_vals = train_merged.index\n",
    "\n",
    "    # --- Top Left: Scatter Plot for ADHD Outcome ---\n",
    "    axs[0, 0].scatter(\n",
    "        x_vals,\n",
    "        train_merged[col],\n",
    "        c=train_merged['ADHD_Outcome'].map(adhd_colors),\n",
    "        alpha=0.7\n",
    "    )\n",
    "    axs[0, 0].set_title(f\"Scatter: {col} vs Participant ID (ADHD)\", fontsize=16, fontweight='bold')\n",
    "    axs[0, 0].set_xlabel(\"Participant ID\", fontsize=14)\n",
    "    axs[0, 0].set_ylabel(col, fontsize=14)\n",
    "    axs[0, 0].grid(True, linestyle='--', alpha=0.5)\n",
    "    legend_elements_adhd = [\n",
    "        Line2D([0], [0], marker='o', color='w', label='Non-ADHD',\n",
    "               markerfacecolor=adhd_colors[0], markersize=10),\n",
    "        Line2D([0], [0], marker='o', color='w', label='ADHD',\n",
    "               markerfacecolor=adhd_colors[1], markersize=10)\n",
    "    ]\n",
    "    axs[0, 0].legend(handles=legend_elements_adhd, title=\"ADHD Outcome\", fontsize=12, title_fontsize=12)\n",
    "\n",
    "    # --- Top Right: KDE Plot for ADHD Outcome ---\n",
    "    sns.kdeplot(\n",
    "        data=train_merged,\n",
    "        x=col,\n",
    "        hue='ADHD_Outcome',\n",
    "        palette=adhd_colors,\n",
    "        fill=True,\n",
    "        common_norm=False,\n",
    "        alpha=0.6,\n",
    "        ax=axs[0, 1]\n",
    "    )\n",
    "    axs[0, 1].set_title(f\"KDE: {col} by ADHD Outcome\", fontsize=16, fontweight='bold')\n",
    "    axs[0, 1].set_xlabel(col, fontsize=14)\n",
    "    axs[0, 1].set_ylabel(\"Density\", fontsize=14)\n",
    "    axs[0, 1].grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    # --- Bottom Left: Scatter Plot for Sex Outcome ---\n",
    "    axs[1, 0].scatter(\n",
    "        x_vals,\n",
    "        train_merged[col],\n",
    "        c=train_merged['Sex_F'].map(sex_colors),\n",
    "        alpha=0.7\n",
    "    )\n",
    "    axs[1, 0].set_title(f\"Scatter: {col} vs Participant ID (Sex)\", fontsize=16, fontweight='bold')\n",
    "    axs[1, 0].set_xlabel(\"Participant ID\", fontsize=14)\n",
    "    axs[1, 0].set_ylabel(col, fontsize=14)\n",
    "    axs[1, 0].grid(True, linestyle='--', alpha=0.5)\n",
    "    legend_elements_sex = [\n",
    "        Line2D([0], [0], marker='o', color='w', label='Male',\n",
    "               markerfacecolor=sex_colors[0], markersize=10),\n",
    "        Line2D([0], [0], marker='o', color='w', label='Female',\n",
    "               markerfacecolor=sex_colors[1], markersize=10)\n",
    "    ]\n",
    "    axs[1, 0].legend(handles=legend_elements_sex, title=\"Sex\", fontsize=12, title_fontsize=12)\n",
    "\n",
    "    # --- Bottom Right: KDE Plot for Sex Outcome ---\n",
    "    sns.kdeplot(\n",
    "        data=train_merged,\n",
    "        x=col,\n",
    "        hue='Sex_F',\n",
    "        palette=sex_colors,\n",
    "        fill=True,\n",
    "        common_norm=False,\n",
    "        alpha=0.6,\n",
    "        ax=axs[1, 1]\n",
    "    )\n",
    "    axs[1, 1].set_title(f\"KDE: {col} by Sex\", fontsize=16, fontweight='bold')\n",
    "    axs[1, 1].set_xlabel(col, fontsize=14)\n",
    "    axs[1, 1].set_ylabel(\"Density\", fontsize=14)\n",
    "    axs[1, 1].grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iLWjQnsCToOV"
   },
   "source": [
    "### [3.2.2.2] ‚Ü™Ô∏è **Connectivity Matrix Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:03.225891Z",
     "iopub.status.busy": "2025-05-02T21:53:03.225515Z",
     "iopub.status.idle": "2025-05-02T21:53:20.971308Z",
     "shell.execute_reply": "2025-05-02T21:53:20.970286Z",
     "shell.execute_reply.started": "2025-05-02T21:53:03.22586Z"
    },
    "id": "IXdl_r_PToOV",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Merge and Aggregate Data\n",
    "# -----------------------------\n",
    "# (Assuming train_df_fcm and train_df_sol are already loaded)\n",
    "\n",
    "# Merge the connectome data with the solution data on 'participant_id'\n",
    "merged_df = pd.merge(train_df_fcm, train_df_sol, on='participant_id')\n",
    "\n",
    "# Identify connectivity columns (exclude 'participant_id')\n",
    "conn_cols = [col for col in train_df_fcm.columns if col != 'participant_id']\n",
    "\n",
    "# Function to sort connectome columns based on node indices extracted from names.\n",
    "def sort_connectome_columns(columns):\n",
    "    def parse_col(col):\n",
    "        # Expected pattern: 'ithrow_jthcolumn' where i and j are integers\n",
    "        m = re.match(r\"(\\d+)throw_(\\d+)thcolumn\", col)\n",
    "        if m:\n",
    "            i = int(m.group(1))\n",
    "            j = int(m.group(2))\n",
    "            return (i, j)\n",
    "        else:\n",
    "            return (float('inf'), float('inf'))\n",
    "    return sorted(columns, key=parse_col)\n",
    "\n",
    "sorted_conn_cols = sort_connectome_columns(conn_cols)\n",
    "\n",
    "# Aggregate connectivity data by ADHD_Outcome and Sex_F (using mean)\n",
    "# (Assuming in train_df_sol: ADHD_Outcome (0/1) and Sex_F (0=Male, 1=Female))\n",
    "adhd_groups = merged_df.groupby('ADHD_Outcome')[sorted_conn_cols].mean()\n",
    "sex_groups  = merged_df.groupby('Sex_F')[sorted_conn_cols].mean()\n",
    "\n",
    "# Function to convert a connectivity vector (of length n*(n-1)/2) into a symmetric matrix.\n",
    "def vector_to_symmetric_matrix(vector, n=200):\n",
    "    mat = np.zeros((n, n))\n",
    "    idx = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            mat[i, j] = vector[idx]\n",
    "            mat[j, i] = vector[idx]\n",
    "            idx += 1\n",
    "    return mat\n",
    "\n",
    "# Create aggregated connectivity matrices:\n",
    "# For ADHD groups: index 1 means ADHD-positive, index 0 means non‚ÄëADHD.\n",
    "adhd_positive_matrix = vector_to_symmetric_matrix(adhd_groups.loc[1].values, n=200)\n",
    "adhd_negative_matrix = vector_to_symmetric_matrix(adhd_groups.loc[0].values, n=200)\n",
    "# For Sex groups: index 1 means Female, index 0 means Male.\n",
    "female_matrix = vector_to_symmetric_matrix(sex_groups.loc[1].values, n=200)\n",
    "male_matrix   = vector_to_symmetric_matrix(sex_groups.loc[0].values, n=200)\n",
    "\n",
    "# Compute difference matrices\n",
    "adhd_diff_matrix = adhd_positive_matrix - adhd_negative_matrix\n",
    "sex_diff_matrix  = female_matrix - male_matrix\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Continuous Heatmap Plots (3 per row)\n",
    "# -----------------------------\n",
    "# We'll create 2 rows (one for ADHD groups and one for Sex groups) and 3 columns per row.\n",
    "fig, axes = plt.subplots(2, 3, figsize=(24, 12))\n",
    "\n",
    "# Define a function to plot a matrix with a lower-triangular mask.\n",
    "def plot_lower_triangle(ax, matrix, title):\n",
    "    mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
    "    sns.heatmap(matrix, mask=mask, cmap=\"coolwarm\", square=True, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "    ax.set_title(title)\n",
    "\n",
    "# ADHD row: column 0: ADHD Positive, 1: ADHD Negative, 2: Difference\n",
    "plot_lower_triangle(axes[0, 0], adhd_positive_matrix, \"ADHD Positive Aggregated Connectome\")\n",
    "plot_lower_triangle(axes[0, 1], adhd_negative_matrix, \"ADHD Negative Aggregated Connectome\")\n",
    "plot_lower_triangle(axes[0, 2], adhd_diff_matrix, \"Difference (ADHD Positive - Negative)\")\n",
    "\n",
    "# Sex row: column 0: Female, 1: Male, 2: Difference\n",
    "plot_lower_triangle(axes[1, 0], female_matrix, \"Female Aggregated Connectome\")\n",
    "plot_lower_triangle(axes[1, 1], male_matrix, \"Male Aggregated Connectome\")\n",
    "plot_lower_triangle(axes[1, 2], sex_diff_matrix, \"Difference (Female - Male)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Thresholding and Binary Graphs\n",
    "# -----------------------------\n",
    "# For binary graphs, we threshold the matrices (e.g. keep only connections above the 75th percentile)\n",
    "def threshold_binary(matrix, percentile=75):\n",
    "    threshold_value = np.percentile(matrix, percentile)\n",
    "    binary_matrix = (matrix > threshold_value).astype(int)\n",
    "    return binary_matrix\n",
    "\n",
    "# Compute binary versions for ADHD groups\n",
    "binary_adhd_positive = threshold_binary(adhd_positive_matrix, percentile=75)\n",
    "binary_adhd_negative = threshold_binary(adhd_negative_matrix, percentile=75)\n",
    "# Difference as binary: subtracting yields -1, 0, or 1\n",
    "binary_adhd_diff = binary_adhd_positive - binary_adhd_negative\n",
    "\n",
    "# Compute binary versions for Sex groups\n",
    "binary_female = threshold_binary(female_matrix, percentile=75)\n",
    "binary_male   = threshold_binary(male_matrix, percentile=75)\n",
    "binary_sex_diff = binary_female - binary_male\n",
    "\n",
    "# Now, create binary heatmaps in a similar layout (2 rows x 3 columns)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(24, 12))\n",
    "\n",
    "# Define a function to plot a binary matrix.\n",
    "def plot_binary_heatmap(ax, matrix, title):\n",
    "    # Using a diverging palette so that -1, 0, 1 can be seen.\n",
    "    # Here, we'll use a custom discrete colormap: -1 (blue), 0 (white), 1 (red)\n",
    "    cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "    sns.heatmap(matrix, cmap=cmap, square=True, cbar=True, ax=ax, vmin=-1, vmax=1)\n",
    "    ax.set_title(title)\n",
    "\n",
    "# ADHD row: binary plots\n",
    "plot_binary_heatmap(axes[0, 0], binary_adhd_positive, \"Binary: ADHD Positive\")\n",
    "plot_binary_heatmap(axes[0, 1], binary_adhd_negative, \"Binary: ADHD Negative\")\n",
    "plot_binary_heatmap(axes[0, 2], binary_adhd_diff, \"Binary Difference (ADHD)\")\n",
    "\n",
    "# Sex row: binary plots\n",
    "plot_binary_heatmap(axes[1, 0], binary_female, \"Binary: Female\")\n",
    "plot_binary_heatmap(axes[1, 1], binary_male, \"Binary: Male\")\n",
    "plot_binary_heatmap(axes[1, 2], binary_sex_diff, \"Binary Difference (Sex)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9rXCKwuToOV"
   },
   "source": [
    "#### ‚ñ∂Ô∏è **Understanding the Connectivity Matrix Plots**\n",
    "\n",
    "The connectivity matrix plots visualize functional relationships between pairs of brain regions, helping us understand how different regions are co-activated during rest.\n",
    "\n",
    "#### ‚è© **Continuous Matrix Heatmaps (Top Figure)**\n",
    "\n",
    "Each heatmap shows a **200 √ó 200 symmetric matrix** where:\n",
    "- **Rows and columns** represent specific brain regions.\n",
    "- **Colors** represent average correlation values (functional connectivity) between those region pairs.\n",
    "  - **Red**: stronger positive correlation (regions activate together).\n",
    "  - **Blue**: negative correlation (regions activate in opposite directions).\n",
    "  - **White**: near-zero correlation (weak/no relationship).\n",
    "\n",
    "These are grouped as:\n",
    "- **ADHD Positive vs Negative**: Visualizes how connectivity patterns differ for ADHD-diagnosed vs. non-diagnosed individuals.\n",
    "- **Female vs Male**: Highlights sex-related differences in brain network structure.\n",
    "- **Difference Plots** (rightmost in each row): Subtract one group from the other (e.g., ADHD+ minus ADHD‚àí), showing where and by how much connectivity differs.  \n",
    "  - The **magnitude range is subtle**, e.g., differences around **¬±0.06 to ¬±0.04**, suggesting mild but potentially meaningful changes in connectivity between groups.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚è© **Binary Matrix Plots (Bottom Figure)**\n",
    "\n",
    "Here, continuous matrices are **thresholded** (e.g., top 25% strongest connections kept) and binarized:\n",
    "- A value of:\n",
    "  - `1`: strong connection present\n",
    "  - `0`: no strong connection\n",
    "- **Difference maps** use values of `-1`, `0`, or `1` to denote group-wise presence/absence:\n",
    "  - `+1`: connection present in one group but not the other.\n",
    "  - `-1`: vice versa.\n",
    "  - `0`: either both have or both lack the connection.\n",
    "\n",
    "These binary heatmaps make **differences more visually stark**, helping isolate which specific brain region pairs differ most between ADHD vs non-ADHD or Female vs Male.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyu1ifz3ToOW"
   },
   "source": [
    "### [3.2.2.3] ‚Ü™Ô∏è **Circular Chord Diagrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:20.972927Z",
     "iopub.status.busy": "2025-05-02T21:53:20.972437Z",
     "iopub.status.idle": "2025-05-02T21:53:25.335742Z",
     "shell.execute_reply": "2025-05-02T21:53:25.334212Z",
     "shell.execute_reply.started": "2025-05-02T21:53:20.972892Z"
    },
    "id": "gp81b1pmToOW",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pycirclize import Circos\n",
    "\n",
    "# -----------------------------\n",
    "# Helper Functions\n",
    "# -----------------------------\n",
    "def aggregate_matrix_by_bins(matrix, num_bins=10):\n",
    "    \"\"\"\n",
    "    Aggregates a full connectome matrix (e.g., 200x200) into a smaller\n",
    "    num_bins x num_bins matrix by averaging over blocks.\n",
    "    \"\"\"\n",
    "    n = matrix.shape[0]\n",
    "    bin_size = n // num_bins\n",
    "    agg_matrix = np.zeros((num_bins, num_bins))\n",
    "    for i in range(num_bins):\n",
    "        for j in range(num_bins):\n",
    "            block = matrix[i*bin_size:(i+1)*bin_size, j*bin_size:(j+1)*bin_size]\n",
    "            agg_matrix[i, j] = block.mean()  # Use mean connection strength\n",
    "    return agg_matrix\n",
    "\n",
    "def save_chord_diagram(matrix, title, filename, cmap='coolwarm', r_lim=(93, 100)):\n",
    "    \"\"\"\n",
    "    Generates a chord diagram for the (binned) connectome matrix using pycirclize,\n",
    "    then saves the resulting figure to a file.\n",
    "    \"\"\"\n",
    "    # Aggregate the full matrix into bins\n",
    "    agg_matrix = aggregate_matrix_by_bins(matrix, num_bins=10)\n",
    "    bin_labels = [f'Bin {i+1}' for i in range(10)]\n",
    "    agg_df = pd.DataFrame(agg_matrix, index=bin_labels, columns=bin_labels)\n",
    "\n",
    "    # Create the chord diagram with pycirclize\n",
    "    circos = Circos.chord_diagram(\n",
    "        agg_df,\n",
    "        start=-265,\n",
    "        end=95,\n",
    "        space=5,\n",
    "        r_lim=r_lim,\n",
    "        cmap=cmap,\n",
    "        label_kws=dict(r=r_lim[0]-1, size=10, color=\"black\"),\n",
    "        link_kws=dict(ec=\"black\", lw=0.5),\n",
    "    )\n",
    "    # (Optional) You can set the title here on the circos figure if needed:\n",
    "    # fig = circos.plotfig(suptitle=title)\n",
    "    fig = circos.plotfig()\n",
    "    fig.savefig(filename)\n",
    "    plt.close(fig)\n",
    "\n",
    "# -----------------------------\n",
    "# Example Aggregated Matrices\n",
    "# -----------------------------\n",
    "# (Assume adhd_positive_matrix, adhd_negative_matrix, female_matrix, male_matrix\n",
    "#  have been previously defined, for example using vector_to_symmetric_matrix)\n",
    "\n",
    "# -----------------------------\n",
    "# Save Chord Diagrams as Images\n",
    "# -----------------------------\n",
    "image_files = {\n",
    "    \"Chord Diagram: ADHD Positive\": \"chord_adhd_positive.png\",\n",
    "    \"Chord Diagram: ADHD Negative\": \"chord_adhd_negative.png\",\n",
    "    \"Chord Diagram: Female\": \"chord_female.png\",\n",
    "    \"Chord Diagram: Male\": \"chord_male.png\",\n",
    "}\n",
    "\n",
    "save_chord_diagram(adhd_positive_matrix, \"Chord Diagram: ADHD Positive\", image_files[\"Chord Diagram: ADHD Positive\"])\n",
    "save_chord_diagram(adhd_negative_matrix, \"Chord Diagram: ADHD Negative\", image_files[\"Chord Diagram: ADHD Negative\"])\n",
    "save_chord_diagram(female_matrix, \"Chord Diagram: Female\", image_files[\"Chord Diagram: Female\"])\n",
    "save_chord_diagram(male_matrix, \"Chord Diagram: Male\", image_files[\"Chord Diagram: Male\"])\n",
    "\n",
    "# Close any lingering figures before creating the subplot grid\n",
    "plt.close('all')\n",
    "\n",
    "# -----------------------------\n",
    "# Load Images into a 2x2 Subplot Grid\n",
    "# -----------------------------\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16, 16))\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "titles = list(image_files.keys())\n",
    "for ax, title in zip(axs.flatten(), titles):\n",
    "    img = plt.imread(image_files[title])\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optionally, delete the temporary image files after display:\n",
    "for file in image_files.values():\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kstnbv7AToOW"
   },
   "source": [
    "#### ‚ñ∂Ô∏è **Circular Chord Diagrams: Quick Breakdown**\n",
    "\n",
    "Chord diagrams summarize brain connectivity by grouping 200 regions into 10 bins and showing how strongly these bins connect.\n",
    "\n",
    "- **Each segment** = a brain region bin (e.g., Bin 1, Bin 2‚Ä¶ Bin 10)  \n",
    "- **Each arc (chord)** = average connection strength between two bins  \n",
    "- **Color**:  \n",
    "  - üîµ Blue = Negative/Low connectivity  \n",
    "  - üî¥ Red = Positive/High connectivity  \n",
    "- **Thickness** = Strength of connection\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "brXcaKmkToOX"
   },
   "source": [
    "### [3.2.2.4] ‚Ü™Ô∏è **PCA: Principal Component Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:25.337117Z",
     "iopub.status.busy": "2025-05-02T21:53:25.336843Z",
     "iopub.status.idle": "2025-05-02T21:53:27.036526Z",
     "shell.execute_reply": "2025-05-02T21:53:27.035693Z",
     "shell.execute_reply.started": "2025-05-02T21:53:25.337095Z"
    },
    "id": "NOsRGDFfToOX",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'  # Use iframe renderer for published notebooks\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a copy of merged_df so the original remains unchanged.\n",
    "df_pca = merged_df.copy()\n",
    "\n",
    "# --- Assume sorted_conn_cols is already defined ---\n",
    "X = df_pca[sorted_conn_cols].values  # shape: (n_subjects, 19900)\n",
    "\n",
    "# Perform PCA with 3 components for the 3D plot\n",
    "pca = PCA(n_components=3)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Add the components to our copy (df_pca) without modifying the original merged_df\n",
    "df_pca = df_pca.copy()  # Ensure we're working on our local copy\n",
    "df_pca['pca1'] = X_pca[:, 0]\n",
    "df_pca['pca2'] = X_pca[:, 1]\n",
    "df_pca['pca3'] = X_pca[:, 2]\n",
    "\n",
    "# Convert target labels to string-based categorical columns\n",
    "df_pca['ADHD_Label'] = df_pca['ADHD_Outcome'].map({0: \"Non-ADHD\", 1: \"ADHD\"})\n",
    "df_pca['Sex_Label'] = df_pca['Sex_F'].map({0: \"Male\", 1: \"Female\"})\n",
    "\n",
    "# Define color palettes for the targets\n",
    "gender_palette = {\"Male\": \"lightblue\", \"Female\": \"lightpink\"}\n",
    "adhd_palette = {\"Non-ADHD\": \"grey\", \"ADHD\": \"#FFDB58\"}\n",
    "\n",
    "# -----------------------\n",
    "# 3D PCA Plot: Two Subplots\n",
    "# -----------------------\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    specs=[[{'type': 'scene'}, {'type': 'scene'}]],\n",
    "    subplot_titles=(\"3D PCA: Colored by ADHD\", \"3D PCA: Colored by Sex\")\n",
    ")\n",
    "\n",
    "# Plot 1: Colored by ADHD Outcome\n",
    "for label in df_pca['ADHD_Label'].unique():\n",
    "    df_subset = df_pca[df_pca['ADHD_Label'] == label]\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=df_subset['pca1'],\n",
    "            y=df_subset['pca2'],\n",
    "            z=df_subset['pca3'],\n",
    "            mode='markers',\n",
    "            name=label,\n",
    "            marker=dict(size=4, color=adhd_palette[label]),\n",
    "            legendgroup=\"ADHD\"\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Plot 2: Colored by Sex\n",
    "for label in df_pca['Sex_Label'].unique():\n",
    "    df_subset = df_pca[df_pca['Sex_Label'] == label]\n",
    "    fig.add_trace(\n",
    "        go.Scatter3d(\n",
    "            x=df_subset['pca1'],\n",
    "            y=df_subset['pca2'],\n",
    "            z=df_subset['pca3'],\n",
    "            mode='markers',\n",
    "            name=label,\n",
    "            marker=dict(size=4, color=gender_palette[label]),\n",
    "            legendgroup=\"Sex\"\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Layout adjustments for the 3D plot\n",
    "fig.update_layout(\n",
    "    height=600,\n",
    "    width=900,\n",
    "    legend_title_text=\"Groups\",\n",
    "    scene=dict(xaxis_title='PC1', yaxis_title='PC2', zaxis_title='PC3'),\n",
    "    scene2=dict(xaxis_title='PC1', yaxis_title='PC2', zaxis_title='PC3'),\n",
    "    margin=dict(l=10, r=10, t=40, b=10)\n",
    ")\n",
    "\n",
    "fig.show()  # Ensure the plot is displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:27.037581Z",
     "iopub.status.busy": "2025-05-02T21:53:27.037336Z",
     "iopub.status.idle": "2025-05-02T21:53:28.176834Z",
     "shell.execute_reply": "2025-05-02T21:53:28.175905Z",
     "shell.execute_reply.started": "2025-05-02T21:53:27.037561Z"
    },
    "id": "fDZsn2xuToOX",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# 2D PCA Plot: Two Subplots\n",
    "# -----------------------\n",
    "# Perform PCA with 2 components for the 2D plot on a fresh copy to avoid altering previous columns.\n",
    "df_pca2 = merged_df.copy()\n",
    "pca2 = PCA(n_components=2)\n",
    "X_pca2 = pca2.fit_transform(df_pca2[sorted_conn_cols].values)\n",
    "df_pca2['pca2_1'] = X_pca2[:, 0]\n",
    "df_pca2['pca2_2'] = X_pca2[:, 1]\n",
    "\n",
    "fig_2d = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=(\"2D PCA Colored by ADHD\", \"2D PCA Colored by Sex\")\n",
    ")\n",
    "\n",
    "# Plot 1: Colored by ADHD Outcome in 2D\n",
    "for label in df_pca2['ADHD_Outcome'].map({0: \"Non-ADHD\", 1: \"ADHD\"}).unique():\n",
    "    subset = df_pca2[df_pca2['ADHD_Outcome'].map({0: \"Non-ADHD\", 1: \"ADHD\"}) == label]\n",
    "    fig_2d.add_trace(\n",
    "        go.Scatter(\n",
    "            x=subset['pca2_1'],\n",
    "            y=subset['pca2_2'],\n",
    "            mode='markers',\n",
    "            marker=dict(color=adhd_palette[label], size=5),\n",
    "            name=label,\n",
    "            legendgroup=\"ADHD\"\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Plot 2: Colored by Sex in 2D\n",
    "for label in df_pca2['Sex_F'].map({0: \"Male\", 1: \"Female\"}).unique():\n",
    "    subset = df_pca2[df_pca2['Sex_F'].map({0: \"Male\", 1: \"Female\"}) == label]\n",
    "    fig_2d.add_trace(\n",
    "        go.Scatter(\n",
    "            x=subset['pca2_1'],\n",
    "            y=subset['pca2_2'],\n",
    "            mode='markers',\n",
    "            marker=dict(color=gender_palette[label], size=5),\n",
    "            name=label,\n",
    "            legendgroup=\"Sex\"\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "fig_2d.update_layout(\n",
    "    height=600,\n",
    "    width=900,\n",
    "    legend_title_text=\"Groups\",\n",
    "    xaxis_title=\"PC1\",\n",
    "    yaxis_title=\"PC2\",\n",
    "    xaxis2_title=\"PC1\",\n",
    "    yaxis2_title=\"PC2\",\n",
    "    margin=dict(l=10, r=10, t=40, b=10)\n",
    ")\n",
    "fig_2d.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oT9PfxTnToOX"
   },
   "source": [
    "#### ‚ñ∂Ô∏è **PCA: Principal Component Analysis (Short Intro)**  \n",
    "PCA is a **dimensionality reduction technique** that transforms high-dimensional data (like 19,900 brain connections per subject) into a smaller number of **uncorrelated components** (PCs) that capture the most variance.  \n",
    "This makes it easier to **visualize patterns**, **detect clusters**, and **compare groups** like ADHD vs. Non-ADHD or Male vs. Female in 2D or 3D.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚è© **3D PCA Scatter Plot**\n",
    "\n",
    "This plot shows subjects in a **3D space** defined by the first **three principal components (PC1, PC2, PC3).**  \n",
    "- **Left plot (ADHD)**: Points are colored by ADHD status. If ADHD and Non-ADHD groups separate in space, it suggests distinct global connectivity patterns.  \n",
    "- **Right plot (Sex)**: Points are colored by sex. Visible separation would imply sex-based differences in brain connectivity structure.\n",
    "\n",
    "üìå **Interpretation**: Clusters or group-wise separations indicate **systematic differences in overall brain connectivity profiles**.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚è© **2D PCA Scatter Plot**\n",
    "\n",
    "Similar to the 3D version, but projected onto just **two components (PC1, PC2)** for a flatter view.  \n",
    "- **Left plot (ADHD)**: Checks for ADHD-related separation in a simplified 2D space.  \n",
    "- **Right plot (Sex)**: Highlights sex-related structure.\n",
    "\n",
    "üìå **Interpretation**: Useful for spotting **clear trends** or **group overlaps** ‚Äî especially helpful when differences are subtle but consistent across dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M424fj9LToOY"
   },
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\"> <strong>[3.2] Categorical Feature Analysis (Survey Data)</strong></span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:28.17806Z",
     "iopub.status.busy": "2025-05-02T21:53:28.177782Z",
     "iopub.status.idle": "2025-05-02T21:53:48.73531Z",
     "shell.execute_reply": "2025-05-02T21:53:48.734224Z",
     "shell.execute_reply.started": "2025-05-02T21:53:28.178036Z"
    },
    "id": "LcKPl5X-ToOY",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "\n",
    "# Define color palettes for target groups and for datasets\n",
    "adhd_palette = {\"Non-ADHD\": \"grey\", \"ADHD\": \"#FFDB58\"}\n",
    "gender_palette = {\"Male\": \"lightblue\", \"Female\": \"lightpink\"}\n",
    "dataset_palette = ['#33638d', '#28ae80']  # For train and test respectively\n",
    "\n",
    "# Ensure you have copies of train_data and test_data\n",
    "train_data = train_data.copy()\n",
    "test_data = test_data.copy()\n",
    "\n",
    "# Add a 'dataset' column to differentiate train and test data\n",
    "train_data['dataset'] = 'train'\n",
    "test_data['dataset'] = 'test'\n",
    "\n",
    "# Combine train and test for the dataset-specific plot\n",
    "combined = pd.concat([train_data, test_data])\n",
    "\n",
    "def create_categorical_plots(feature):\n",
    "    sns.set_style('whitegrid')\n",
    "\n",
    "    # Create a figure with 1 row and 4 columns\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(24, 5))\n",
    "\n",
    "    # ---------------------\n",
    "    # Plot 1: Overall Pie Chart\n",
    "    # ---------------------\n",
    "    value_counts = combined[feature].value_counts()\n",
    "    threshold = 0.05 * value_counts.sum()\n",
    "    filtered_values = value_counts[value_counts >= threshold]\n",
    "    if value_counts[value_counts < threshold].sum() > 0:\n",
    "        filtered_values['Other'] = value_counts[value_counts < threshold].sum()\n",
    "\n",
    "    wedges, texts, autotexts = axes[0].pie(\n",
    "        filtered_values,\n",
    "        autopct=lambda p: f'{p:.1f}%' if p > 5 else '',\n",
    "        colors=sns.color_palette(\"viridis\", len(filtered_values)),\n",
    "        startangle=140,\n",
    "        wedgeprops=dict(width=0.3),\n",
    "        explode=[0.05 if count > threshold else 0 for count in filtered_values],\n",
    "        textprops={'fontsize': 10}\n",
    "    )\n",
    "    axes[0].set_title(\"\\n\".join(textwrap.wrap(\n",
    "        f\"Pie Chart for {feature}: {dict_df.loc[dict_df['Field'] == feature, 'Description'].values[0]}\", width=50)))\n",
    "\n",
    "    # ---------------------\n",
    "    # Plot 2: Countplot by Dataset (Train vs Test)\n",
    "    # ---------------------\n",
    "    sns.countplot(\n",
    "        data=combined,\n",
    "        x=feature,\n",
    "        hue='dataset',\n",
    "        palette=dataset_palette,\n",
    "        ax=axes[1]\n",
    "    )\n",
    "    axes[1].set_xlabel(feature)\n",
    "    axes[1].set_ylabel(\"Count\")\n",
    "    axes[1].set_title(\"\\n\".join(textwrap.wrap(f\"Countplot for {feature} by Dataset\", width=50)))\n",
    "    axes[1].tick_params(axis='x', rotation=30)\n",
    "\n",
    "    # For the following plots, ensure the feature remains categorical (do not convert to numeric)\n",
    "    \n",
    "    # ---------------------\n",
    "    # Plot 3: Countplot for ADHD Outcome (Train only)\n",
    "    # ---------------------\n",
    "    train_data['ADHD_Label'] = train_data['ADHD_Outcome'].map({0: \"Non-ADHD\", 1: \"ADHD\"})\n",
    "    sns.countplot(\n",
    "        data=train_data,\n",
    "        x=feature,\n",
    "        hue='ADHD_Label',\n",
    "        palette=adhd_palette,\n",
    "        ax=axes[2]\n",
    "    )\n",
    "    axes[2].set_xlabel(feature)\n",
    "    axes[2].set_ylabel(\"Count\")\n",
    "    axes[2].set_title(\"\\n\".join(textwrap.wrap(f\"Distribution of {feature} by ADHD Outcome\", width=50)))\n",
    "    axes[2].legend()\n",
    "\n",
    "    # ---------------------\n",
    "    # Plot 4: Countplot for Sex (Train only)\n",
    "    # ---------------------\n",
    "    train_data['Sex_Label'] = train_data['Sex_F'].map({0: \"Male\", 1: \"Female\"})\n",
    "    sns.countplot(\n",
    "        data=train_data,\n",
    "        x=feature,\n",
    "        hue='Sex_Label',\n",
    "        palette=gender_palette,\n",
    "        ax=axes[3]\n",
    "    )\n",
    "    axes[3].set_xlabel(feature)\n",
    "    axes[3].set_ylabel(\"Count\")\n",
    "    axes[3].set_title(\"\\n\".join(textwrap.wrap(f\"Distribution of {feature} by Sex\", width=50)))\n",
    "    axes[3].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Perform univariate analysis for each categorical variable\n",
    "for feature in categorical_variables:\n",
    "    create_categorical_plots(feature)\n",
    "\n",
    "# Cleanup: Drop temporary columns\n",
    "train_data.drop(['dataset', 'ADHD_Label', 'Sex_Label'], axis=1, inplace=True)\n",
    "test_data.drop(['dataset'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#ffffff; font-size: 1%;\">SW-Key-Features-Insights</span>\n",
    "<div style=\"background-color:#E8F8F5; border-left:8px solid #1ABC9C; padding:20px; border-radius:8px; font-size:14px; color:#000000;\">\n",
    "  <h3 style=\"font-size:20px; margin-bottom:10px;\">ü§îüíÅ‚Äç‚ôÄÔ∏èSo What?! <strong>(üìù Key Insights¬†‚Äë¬†Summary)</strong></h3>\n",
    "  <hr>\n",
    "  <ul>\n",
    "    <li><strong>Sampling &amp; Site Effects (<code>Enroll¬†Year</code>, <code>Study¬†Site</code>, <code>Scan¬†Location</code>):</strong> Training data are concentrated in <code>2016‚Äë2019</code> and in two sites, whereas the test set shifts to <code>2022+</code> and a different scan location. These temporal‚Äësite drifts must be harmonised (e.g., ComBat) to avoid data‚Äëleakage‚Äëdriven performance.</li>\n",
    "    <li><strong>Socio‚Äëeconomic Gradient (Barratt Indices):</strong> Lower parental education (‚â§‚ÄØhigh‚Äëschool) and lower occupational prestige codes cluster with higher <code>ADHD</code> prevalence, suggesting that family SES is an important‚Äîbut potentially confounded‚Äîpredictor.</li>\n",
    "    <li><strong>Parenting Style &amp; Discipline (<code>Corporal¬†Punishment</code>):</strong> Scores escalate in the <code>ADHD</code> group, hinting that harsher discipline may coexist with, or respond to, behavioural dysregulation.</li>\n",
    "    <li><strong>Behavioural Symptom Scales (SDQ Sub‚Äëscales):</strong> Marked, monotonic shifts‚Äîespecially on <code>Conduct</code>, <code>Hyperactivity</code>, and overall <code>Impact</code>‚Äîdifferentiate <code>ADHD</code> from <code>non‚ÄëADHD</code>, making them high‚Äëvalue features.</li>\n",
    "    <li><strong>Protective Traits (<code>Prosocial</code>):</strong> Prosocial behaviours are notably reduced in the <code>ADHD</code> cohort, the mirror image of the elevated problem‚Äëscores above, rounding out the behavioural profile.</li>\n",
    "  </ul>\n",
    "\n",
    "  <h3 style=\"font-size:20px; margin-bottom:10px;\">ü§îüíÅ‚Äç‚ôÄÔ∏èSo What?! <strong>(üìù Key Insights¬†‚Äë¬†Detailed)</strong></h3>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 1 -->\n",
    "  <p><strong>1Ô∏è‚É£¬†Basic Year of Enrolment <code>(Basic_Demos_Enroll_Year)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Highly left‚Äëtruncated timeline‚Äî<code>2017‚Äë2019</code> cover >‚ÄØ65‚ÄØ% of training rows and host the highest <code>ADHD</code> counts; the entire test set shifts to <code>2022‚Äë2023</code>.</li>\n",
    "    <li><strong>Interpretation:</strong> Year acts as a proxy for protocol evolution and recruiting waves. Without stratified CV, models might overfit year‚Äëspecific quirks rather than neuro‚Äëbehavioural signals; consider removing or re‚Äëencoding.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 2 -->\n",
    "  <p><strong>2Ô∏è‚É£¬†Site of Phenotypic Testing <code>(Basic_Demos_Study_Site)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Three main sites‚Äî<code>1,¬†3,¬†4</code>. Site¬†1 dominates training (43‚ÄØ%) but is absent from the test set; Site¬†4 is 72‚ÄØ% of test.</li>\n",
    "    <li><strong>Interpretation:</strong> Site encapsulates scanner, technician, and demographic differences. Its shift between splits magnifies domain‚Äëshift risk; mandatory harmonisation or domain‚Äëadaptation is advised.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 3 -->\n",
    "  <p><strong>3Ô∏è‚É£¬†Child Ethnicity <code>(PreInt_Demos_Fam_Child_Ethnicity)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Majority coded <code>0‚ÄØ=‚ÄØNot‚ÄëHispanic</code> (~66‚ÄØ%), with <code>Hispanic¬†(1)</code> at 23‚ÄØ%. Slightly higher ADHD counts among non‚ÄëHispanic children.</li>\n",
    "    <li><strong>Interpretation:</strong> Ethnicity may intertwine with SES and access to services; the modest imbalance means cautious weighting rather than aggressive feature pruning.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 4 -->\n",
    "  <p><strong>4Ô∏è‚É£¬†Child Race <code>(PreInt_Demos_Fam_Child_Race)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Predominantly <code>White¬†(0)</code> (~49‚ÄØ%) and \"Other/Refused\"¬†(8) (~16‚ÄØ%). ADHD proportions mirror availability rather than showing large race effects.</li>\n",
    "    <li><strong>Interpretation:</strong> The sample‚Äôs racial skew limits generalisability; race codes may still capture latent SES or cultural factors but risk spurious correlations.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 5 -->\n",
    "  <p><strong>5Ô∏è‚É£¬†Scan Location <code>(MRI_Track_Scan_Location)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Two scanners account for >‚ÄØ70‚ÄØ% of rows (<code>Loc¬†2¬†&amp;¬†3</code>). The test set is almost exclusively <code>Loc¬†3/4</code>; ADHD prevalence is highest at <code>Loc¬†2¬†&amp;¬†3</code>.</li>\n",
    "    <li><strong>Interpretation:</strong> Location reflects hardware and software versions. It is a powerful‚Äîbut potentially confounding‚Äîfeature for connectomic data; batch‚Äëeffect correction or domain‚Äëspecific CV folds are needed.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 6 -->\n",
    "  <p><strong>6Ô∏è‚É£¬†Parent¬†1 Education Level <code>(Barratt_Barratt_P1_Edu)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Scores cluster at <code>18¬†&amp;¬†21</code> (college/graduate). ADHD counts rise as education drops (peak odds ratio at <code>‚â§‚ÄØ15</code>).</li>\n",
    "    <li><strong>Interpretation:</strong> Lower educational attainment may signal reduced resources for early intervention, aligning with literature on ADHD and SES.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 7 -->\n",
    "  <p><strong>7Ô∏è‚É£¬†Parent¬†1 Occupation <code>(Barratt_Barratt_P1_Occ)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Trimodal distribution‚Äîprofessional codes (<code>35/45</code>), service (<code>30/40</code>), and unemployed¬†(0). ADHD density is greatest in lower‚Äëprestige bands (0‚Äë25).</li>\n",
    "    <li><strong>Interpretation:</strong> Occupational prestige complements education as an SES marker; together they strengthen models but warrant multicollinearity checks.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 8 -->\n",
    "  <p><strong>8Ô∏è‚É£¬†Parent¬†2 Education Level <code>(Barratt_Barratt_P2_Edu)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Higher missingness (15‚ÄØ%). Where present, the mode is <code>21</code>; ADHD likelihood again rises in lower bands and in missing values.</li>\n",
    "    <li><strong>Interpretation:</strong> Treat \"missing\" as informative‚Äîoften single‚Äëparent or data‚Äëpoor households. Imputation strategy should preserve that signal.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 9 -->\n",
    "  <p><strong>9Ô∏è‚É£¬†Parent¬†2 Occupation <code>(Barratt_Barratt_P2_Occ)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Key‚Äëcap <code>45</code> (professional) dominates but ADHD prevalence escalates in semi‚Äëskilled (<code>30/35</code>) and in <code>missing</code>.</li>\n",
    "    <li><strong>Interpretation:</strong> Reinforces the SES gradient; combined parental occupation indices may capture family stability dimensions.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 10 -->\n",
    "  <p><strong>üîü¬†Color Vision Score <code>(ColorVision_CV_Score)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Ceiling effect‚Äî<code>14/14</code> on 77‚ÄØ% of cases; only a long, sparse tail below.</li>\n",
    "    <li><strong>Interpretation:</strong> Minimal variance limits predictive value; treat as QC flag rather than a modelling feature.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 11 -->\n",
    "  <p><strong>1Ô∏è‚É£1Ô∏è‚É£¬†Corporal Punishment Score <code>(APQ_P_APQ_P_CP)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Mode at <code>3</code>; ADHD subjects show heavier right‚Äëtail (‚â•‚ÄØ5).</li>\n",
    "    <li><strong>Interpretation:</strong> Higher corporal punishment aligns with externalising behaviours; could serve as psychosocial predictor but may introduce reporter bias.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 12 -->\n",
    "  <p><strong>1Ô∏è‚É£2Ô∏è‚É£¬†Conduct Problems <code>(SDQ_SDQ_Conduct_Problems)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Clear gradient‚Äîcounts drop monotonically from <code>0</code> to <code>10</code> but ADHD proportion rises sharply beyond <code>2</code>.</li>\n",
    "    <li><strong>Interpretation:</strong> High conduct scores are a hallmark externalising symptom; valuable standalone predictor and consistent with DSM profiles.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 13 -->\n",
    "  <p><strong>1Ô∏è‚É£3Ô∏è‚É£¬†Emotional Problems <code>(SDQ_SDQ_Emotional_Problems)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Right‚Äëskewed; ADHD subjects populate upper deciles (‚â•‚ÄØ6) twice as often as non‚ÄëADHD.</li>\n",
    "    <li><strong>Interpretation:</strong> Captures internalising comorbidity (anxiety/depression) frequently co‚Äëoccurring with ADHD, aiding nuanced classification.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 14 -->\n",
    "  <p><strong>1Ô∏è‚É£4Ô∏è‚É£¬†Overall Impact Score <code>(SDQ_SDQ_Generating_Impact)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Multimodal, but ADHD children cluster in the upper modes (6‚Äë10).</li>\n",
    "    <li><strong>Interpretation:</strong> Summarises functional impairment across settings; one of the strongest signal‚Äëto‚Äënoise ratios for ADHD diagnosis.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 15 -->\n",
    "  <p><strong>1Ô∏è‚É£5Ô∏è‚É£¬†Hyperactivity Scale <code>(SDQ_SDQ_Hyperactivity)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Bimodal‚ÄîADHD peaks at <code>9‚Äë10</code>, non‚ÄëADHD at <code>2‚Äë4</code>; sex gap mirrors ADHD gap (males higher).</li>\n",
    "    <li><strong>Interpretation:</strong> Direct symptomatic measure; expect high feature importance in tree‚Äëbased models.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 16 -->\n",
    "  <p><strong>1Ô∏è‚É£6Ô∏è‚É£¬†Peer Problems Scale <code>(SDQ_SDQ_Peer_Problems)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Long right tail; ADHD share increases steadily from <code>3+</code>. Females slightly less impaired than males.</li>\n",
    "    <li><strong>Interpretation:</strong> Peer difficulties reflect social repercussions of ADHD; complements conduct &amp; hyperactivity sub‚Äëscales.</li>\n",
    "  </ul>\n",
    "  <hr>\n",
    "\n",
    "  <!-- 17 -->\n",
    "  <p><strong>1Ô∏è‚É£7Ô∏è‚É£¬†Prosocial Scale <code>(SDQ_SDQ_Prosocial)</code></strong></p>\n",
    "  <ul>\n",
    "    <li><strong>Pattern:</strong> Inverted distribution‚Äînon‚ÄëADHD cluster at the ceiling (<code>9‚Äë10</code>), ADHD distribute across mid‚Äërange (5‚Äë8).</li>\n",
    "    <li><strong>Interpretation:</strong> Lower prosocial behaviours mark social reciprocity deficits often noted in ADHD; useful negative predictor when combined with externalising scores.</li>\n",
    "  </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zhp0ovASToOY"
   },
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\"> <strong>[3.3] Target Feature Analysis (Univariate Analysis)</strong></span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:48.736997Z",
     "iopub.status.busy": "2025-05-02T21:53:48.736571Z",
     "iopub.status.idle": "2025-05-02T21:53:49.805441Z",
     "shell.execute_reply": "2025-05-02T21:53:49.804491Z",
     "shell.execute_reply.started": "2025-05-02T21:53:48.736959Z"
    },
    "id": "sBJA-33GToOY",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "\n",
    "# Define default color palettes for non-target variables\n",
    "pie_chart_palette = ['#33638d', '#28ae80', '#d3eb0c', '#ff9a0b', '#7e03a8', '#35b779',\n",
    "                       '#fde725', '#440154', '#90d743', '#482173', '#22a884', '#f8961e']\n",
    "countplot_color = '#5C67A3'\n",
    "\n",
    "# Define custom palettes for the target variables\n",
    "sex_color_map = {0: 'lightblue', 1: 'lightpink'}\n",
    "adhd_color_map = {0: 'grey', 1: '#FFDB58'}\n",
    "\n",
    "# Function to create and display a row of plots for a single categorical variable\n",
    "def create_categorical_plots(variable):\n",
    "    sns.set_style('whitegrid')\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # ---------------------\n",
    "    # Pie Chart - Handling many categories\n",
    "    # ---------------------\n",
    "    plt.subplot(1, 2, 1)\n",
    "\n",
    "    # Get combined counts from train and test\n",
    "    combined = pd.concat([train_data, test_data])\n",
    "    value_counts = combined[variable].value_counts()\n",
    "    total = value_counts.sum()\n",
    "\n",
    "    # For target variables, enforce an order and custom palette\n",
    "    if variable == 'Sex_F':\n",
    "        order = [0, 1]  # Male then Female\n",
    "        value_counts = value_counts.reindex(order).dropna()\n",
    "        custom_pie_palette = [sex_color_map[val] for val in order if val in value_counts.index]\n",
    "    elif variable == 'ADHD_Outcome':\n",
    "        order = [0, 1]  # Non-ADHD then ADHD\n",
    "        value_counts = value_counts.reindex(order).dropna()\n",
    "        custom_pie_palette = [adhd_color_map[val] for val in order if val in value_counts.index]\n",
    "    else:\n",
    "        custom_pie_palette = pie_chart_palette[:len(value_counts)]\n",
    "\n",
    "    # Combine small categories (<5%) into \"Other\" (only for non-target variables)\n",
    "    threshold = 0.05 * total\n",
    "    if variable not in ['Sex_F', 'ADHD_Outcome']:\n",
    "        filtered_values = value_counts[value_counts >= threshold]\n",
    "        other_total = value_counts[value_counts < threshold].sum()\n",
    "        if other_total > 0:\n",
    "            filtered_values['Other'] = other_total\n",
    "        value_counts = filtered_values\n",
    "        # Adjust palette and explode for the filtered categories\n",
    "        custom_pie_palette = pie_chart_palette[:len(value_counts)]\n",
    "        explode = [0.05 if count >= threshold else 0 for count in value_counts]\n",
    "    else:\n",
    "        explode = [0.05] * len(value_counts)  # Slight explode for both bars\n",
    "\n",
    "    wedges, texts, autotexts = plt.pie(\n",
    "        value_counts,\n",
    "        autopct=lambda p: f'{p:.1f}%' if p > 5 else '',  # Hide labels < 5%\n",
    "        colors=custom_pie_palette,\n",
    "        startangle=140,\n",
    "        wedgeprops=dict(width=0.3),\n",
    "        explode=explode,\n",
    "        textprops={'fontsize': 10}\n",
    "    )\n",
    "\n",
    "    title_text = dict_df.loc[dict_df['Field'] == variable, 'Description'].values[0] \\\n",
    "                    if variable in dict_df['Field'].values else variable\n",
    "    plt.title(\"\\n\".join(textwrap.wrap(f\"Pie Chart for {title_text}  [TRAIN]\", width=50)))\n",
    "    plt.legend(value_counts.index, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "    # ---------------------\n",
    "    # Bar Graph (Countplot)\n",
    "    # ---------------------\n",
    "    plt.subplot(1, 2, 2)\n",
    "    # For target variables, use a custom palette; otherwise, use default color.\n",
    "    if variable == 'Sex_F':\n",
    "        order = [0, 1]\n",
    "        sns.countplot(\n",
    "            data=combined,\n",
    "            x=variable,\n",
    "            palette=sex_color_map,\n",
    "            order=order\n",
    "        )\n",
    "    elif variable == 'ADHD_Outcome':\n",
    "        order = [0, 1]\n",
    "        sns.countplot(\n",
    "            data=combined,\n",
    "            x=variable,\n",
    "            palette=adhd_color_map,\n",
    "            order=order\n",
    "        )\n",
    "    else:\n",
    "        sns.countplot(\n",
    "            data=combined,\n",
    "            x=variable,\n",
    "            color=countplot_color,\n",
    "            alpha=0.8\n",
    "        )\n",
    "\n",
    "    plt.xlabel(variable)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"\\n\".join(textwrap.wrap(f\"Bar Graph for {title_text}  [TRAIN]\", width=50)))\n",
    "    plt.xticks(rotation=30)\n",
    "\n",
    "    # Adjust spacing between subplots\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plots\n",
    "    plt.show()\n",
    "\n",
    "# Perform univariate analysis for each categorical variable in your target_variables list\n",
    "for variable in target_variables:\n",
    "    create_categorical_plots(variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQCLdKuEToOY"
   },
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\"> <strong>[3.4] Bivariate Analysis (Survey Data)</strong></span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:49.807138Z",
     "iopub.status.busy": "2025-05-02T21:53:49.806762Z",
     "iopub.status.idle": "2025-05-02T21:53:53.617783Z",
     "shell.execute_reply": "2025-05-02T21:53:53.616725Z",
     "shell.execute_reply.started": "2025-05-02T21:53:49.807104Z"
    },
    "id": "PJMY6RowToOY",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Adding variables to the existing list\n",
    "test_variables = categorical_variables+numerical_variables\n",
    "train_variables = categorical_variables+numerical_variables+ target_variables\n",
    "\n",
    "# Calculate correlation matrices for train_data and test_data\n",
    "corr_train = train_data[train_variables].corr()\n",
    "corr_test = test_data[test_variables].corr()\n",
    "\n",
    "# Create masks for the upper triangle\n",
    "mask_train = np.triu(np.ones_like(corr_train, dtype=bool))\n",
    "mask_test = np.triu(np.ones_like(corr_test, dtype=bool))\n",
    "\n",
    "# Set the text size and rotation\n",
    "annot_kws = {\"size\": 6, \"rotation\": 45}\n",
    "\n",
    "# Generate heatmaps for train_data\n",
    "plt.figure(figsize=(10, 20))\n",
    "plt.subplot(2, 1, 1)\n",
    "ax_train = sns.heatmap(corr_train, mask=mask_train, cmap='viridis', annot=True,\n",
    "                      square=True, linewidths=.5, xticklabels=1, yticklabels=1, annot_kws=annot_kws)\n",
    "plt.title('Correlation Heatmap - Train Data')\n",
    "\n",
    "# Generate heatmaps for test_data\n",
    "plt.subplot(2, 1, 2)\n",
    "ax_test = sns.heatmap(corr_test, mask=mask_test, cmap='viridis', annot=True,\n",
    "                     square=True, linewidths=.5, xticklabels=1, yticklabels=1, annot_kws=annot_kws)\n",
    "plt.title('Correlation Heatmap - Test Data')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:53.619379Z",
     "iopub.status.busy": "2025-05-02T21:53:53.619102Z",
     "iopub.status.idle": "2025-05-02T21:53:53.906246Z",
     "shell.execute_reply": "2025-05-02T21:53:53.905206Z",
     "shell.execute_reply.started": "2025-05-02T21:53:53.619357Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a contingency table (crosstab)\n",
    "crosstab = pd.crosstab(train_data['Sex_F'], train_data['ADHD_Outcome'])\n",
    "# Optionally, you can convert counts to percentages if desired:\n",
    "crosstab_percent = crosstab.apply(lambda r: r / r.sum() * 100, axis=1)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(crosstab, annot=True, fmt=\"d\", cmap=\"viridis\")\n",
    "plt.xlabel(\"ADHD Outcome (0: Non-ADHD, 1: ADHD)\")\n",
    "plt.ylabel(\"Sex (0: Male, 1: Female)\")\n",
    "plt.title(\"Crosstab of Sex vs. ADHD Outcome\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:53.907768Z",
     "iopub.status.busy": "2025-05-02T21:53:53.9074Z",
     "iopub.status.idle": "2025-05-02T21:53:55.279755Z",
     "shell.execute_reply": "2025-05-02T21:53:55.278749Z",
     "shell.execute_reply.started": "2025-05-02T21:53:53.907738Z"
    },
    "id": "YICjHgSzToOY",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute correlation matrix\n",
    "test_variables = categorical_variables + numerical_variables\n",
    "train_variables = categorical_variables + numerical_variables + target_variables\n",
    "corr_train = train_data[train_variables].corr()[target_variables]\n",
    "\n",
    "# Setup for vertical bar plots (features on x-axis)\n",
    "num_targets = len(target_variables)\n",
    "fig, axs = plt.subplots(num_targets, 1, figsize=(len(train_variables) * 0.3 + 2, 8 * num_targets), constrained_layout=True)\n",
    "\n",
    "if num_targets == 1:\n",
    "    axs = [axs]\n",
    "\n",
    "for i, target in enumerate(target_variables):\n",
    "    sorted_corr = corr_train[target].drop(target).sort_values(ascending=False)\n",
    "    colors = sns.color_palette(\"viridis\", n_colors=len(sorted_corr))\n",
    "\n",
    "    sns.barplot(y=sorted_corr.values, x=sorted_corr.index, palette=colors, ax=axs[i])\n",
    "    axs[i].set_title(f\"Correlation with {target}\", fontsize=14)\n",
    "    axs[i].set_ylabel(\"Correlation\", fontsize=12)\n",
    "    axs[i].set_xlabel(\"Features\", fontsize=12)\n",
    "    axs[i].tick_params(axis='x', rotation=90)\n",
    "    axs[i].tick_params(axis='y', labelsize=10)\n",
    "\n",
    "plt.suptitle(\"Feature Correlations with Target Variables\", fontsize=16, y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": true
   },
   "source": [
    "# <span style=\"color:#ffffff; font-size: 1%;\">[4] üõ†Ô∏è Data Preprocessing</span>\n",
    "### <span style=\"color:#ffffff; font-size: 1%;\">Data Preprocessing</span>\n",
    "\n",
    "<div style=\" border-bottom: 8px solid #E6A600; overflow: hidden; border-radius: 10px; height: 45px; width: 100%; display: flex;\">\n",
    "  <div style=\"height: 100%; width: 65%; background-color: #C2185B; float: left; text-align: center; display: flex; justify-content: center; align-items: center; font-size: 25px; \">\n",
    "    <b><span style=\"color: #ffffff; padding: 20px 20px;\">[4] üõ†Ô∏èüßπ Data Preprocessing</span></b>\n",
    "  </div>\n",
    "  <div style=\"height: 100%; width: 35%; background-image: url('https://www.kaggle.com/competitions/90566/images/header'); background-size: cover; background-position: center; float: left; border-top-right-radius: 10px; border-bottom-right-radius: 4px;\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\">[4.1] <strong> Feature Engineering </strong></span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature extraction** is the cornerstone of effective modeling‚Äîit transforms raw, high-dimensional data into a structured and informative representation that a model can *actually learn from*. Rather than feeding a model everything and hoping it figures things out, **we proactively craft features** that emphasize the signal and suppress the noise.\n",
    "\n",
    "In real-world datasets, the **raw inputs rarely expose their predictive power directly**. Instead, we derive features that **encode domain knowledge**, emphasize **statistical patterns**, and **capture non-obvious relationships** across variables. This step is not just preprocessing‚Äîit's **the bridge between raw data and intelligent modeling**.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå **Why Feature Extraction Matters?**  \n",
    "‚úÖ **Uncovers latent structures** ‚Üí Helps models capture meaningful and subtle patterns.  \n",
    "‚úÖ **Improves generalization** ‚Üí Removes irrelevant variance that could lead to overfitting.  \n",
    "‚úÖ **Boosts model performance** ‚Üí Good features can dramatically increase predictive accuracy.  \n",
    "‚úÖ **Enables interpretability** ‚Üí Meaningful features make model outputs more explainable.  \n",
    "‚úÖ **Optimizes efficiency** ‚Üí Lower dimensionality means faster training and better scalability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:55.281112Z",
     "iopub.status.busy": "2025-05-02T21:53:55.280795Z",
     "iopub.status.idle": "2025-05-02T21:53:55.29699Z",
     "shell.execute_reply": "2025-05-02T21:53:55.295796Z",
     "shell.execute_reply.started": "2025-05-02T21:53:55.281086Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "LOG_VARS = [\n",
    "    \"EHQ_EHQ_Total\",\n",
    "    \"APQ_P_APQ_P_ID\", \"APQ_P_APQ_P_INV\", \"APQ_P_APQ_P_OPD\",\n",
    "    \"APQ_P_APQ_P_PM\", \"APQ_P_APQ_P_PP\",\n",
    "    \"SDQ_SDQ_Difficulties_Total\",\n",
    "    \"SDQ_SDQ_Externalizing\", \"SDQ_SDQ_Internalizing\",\n",
    "    \"SDQ_SDQ_Conduct_Problems\", \"SDQ_SDQ_Emotional_Problems\",\n",
    "    \"SDQ_SDQ_Hyperactivity\", \"SDQ_SDQ_Peer_Problems\",\n",
    "    \"SDQ_SDQ_Generating_Impact\", \"SDQ_SDQ_Prosocial\"\n",
    "]\n",
    "\n",
    "PARENT_EDU    = [\"Barratt_Barratt_P1_Edu\", \"Barratt_Barratt_P2_Edu\"]\n",
    "PARENT_OCC    = [\"Barratt_Barratt_P1_Occ\", \"Barratt_Barratt_P2_Occ\"]\n",
    "PARENT_SCORES = [\"APQ_P_APQ_P_CP\", \"APQ_P_APQ_P_PM\", \"APQ_P_APQ_P_PP\"]\n",
    "SDQ_EXTERNAL  = [\"SDQ_SDQ_Conduct_Problems\", \"SDQ_SDQ_Hyperactivity\"]\n",
    "SDQ_INTERNAL  = [\"SDQ_SDQ_Emotional_Problems\", \"SDQ_SDQ_Peer_Problems\"]\n",
    "\n",
    "def add_engineered_features(train_df: pd.DataFrame,\n",
    "                            test_df:  pd.DataFrame):\n",
    "    # SES composites\n",
    "    ses_cols   = PARENT_EDU + PARENT_OCC\n",
    "    ses_scaler = StandardScaler().fit(train_df[ses_cols].fillna(0))\n",
    "    for df in (train_df, test_df):\n",
    "        df[\"SES_zmean\"]        = ses_scaler.transform(df[ses_cols].fillna(0)).mean(axis=1)\n",
    "        df[\"SES_gap\"]          = (df[PARENT_EDU[0]] - df[PARENT_EDU[1]]).abs() \\\n",
    "                                + (df[PARENT_OCC[0]] - df[PARENT_OCC[1]]).abs()\n",
    "        df[\"SES_missing_cnt\"]  = df[ses_cols].isna().sum(axis=1)\n",
    "\n",
    "    # Parenting‚Äêstyle axis\n",
    "    ps_scaler = StandardScaler().fit(train_df[PARENT_SCORES].fillna(0))\n",
    "    for df in (train_df, test_df):\n",
    "        z      = ps_scaler.transform(df[PARENT_SCORES].fillna(0))\n",
    "        zdf    = pd.DataFrame(z, columns=[c + \"_z\" for c in PARENT_SCORES], index=df.index)\n",
    "        df[zdf.columns] = zdf\n",
    "        df[\"Parenting_harsh_vs_pos\"] = df[\"APQ_P_APQ_P_CP_z\"] - df[\"APQ_P_APQ_P_PP_z\"]\n",
    "\n",
    "    # SDQ aggregates & ratio\n",
    "    for df in (train_df, test_df):\n",
    "        df[\"SDQ_external_sum\"] = df[SDQ_EXTERNAL].sum(axis=1)\n",
    "        df[\"SDQ_internal_sum\"] = df[SDQ_INTERNAL].sum(axis=1)\n",
    "        df[\"SDQ_ext_int_ratio\"] = df[\"SDQ_external_sum\"] / (df[\"SDQ_internal_sum\"] + 1e-3)\n",
    "\n",
    "    # Temporal & domain‚Äêshift guards\n",
    "    med_year = train_df[\"Basic_Demos_Enroll_Year\"].median()\n",
    "    for df in (train_df, test_df):\n",
    "        df[\"Enroll_recency\"]  = df[\"Basic_Demos_Enroll_Year\"] - med_year\n",
    "        df[\"Enroll_post2020\"] = (df[\"Basic_Demos_Enroll_Year\"] >= 2020).astype(int)\n",
    "    seen_sites = train_df[\"Basic_Demos_Study_Site\"].unique()\n",
    "    seen_locs  = train_df[\"MRI_Track_Scan_Location\"].unique()\n",
    "    test_df[\"Unseen_site\"]     = (~test_df[\"Basic_Demos_Study_Site\"].isin(seen_sites)).astype(int)\n",
    "    test_df[\"Unseen_scan_loc\"] = (~test_df[\"MRI_Track_Scan_Location\"].isin(seen_locs)).astype(int)\n",
    "    train_df[\"Unseen_site\"]    = 0\n",
    "    train_df[\"Unseen_scan_loc\"]= 0\n",
    "\n",
    "    # Age standardisation\n",
    "    age_mean = train_df[\"MRI_Track_Age_at_Scan\"].mean()\n",
    "    age_std  = train_df[\"MRI_Track_Age_at_Scan\"].std()\n",
    "    for df in (train_df, test_df):\n",
    "        df[\"Age_z\"] = (df[\"MRI_Track_Age_at_Scan\"] - age_mean) / age_std\n",
    "\n",
    "    # Log transforms\n",
    "    for col in LOG_VARS:\n",
    "        for df in (train_df, test_df):\n",
    "            if col in df.columns:\n",
    "                df[col + \"_log\"] = np.log1p(df[col].clip(lower=0))\n",
    "\n",
    "    # --- ensure no NaNs anywhere ---\n",
    "    train_df.fillna(0, inplace=True)\n",
    "    test_df.fillna(0,  inplace=True)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:55.298416Z",
     "iopub.status.busy": "2025-05-02T21:53:55.298113Z",
     "iopub.status.idle": "2025-05-02T21:53:55.387861Z",
     "shell.execute_reply": "2025-05-02T21:53:55.386898Z",
     "shell.execute_reply.started": "2025-05-02T21:53:55.29839Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = add_engineered_features(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#ffffff; font-size:1%;\">SW-Key-Features-Insights</span>\n",
    "\n",
    "<div style=\"background:#E8F8F5;border-left:8px solid #1ABC9C;padding:20px;border-radius:8px;font-size:14px;color:#000\"> <h3 style=\"font-size:20px;margin-bottom:10px;\">ü§îüíÅ‚Äç‚ôÄÔ∏èSo What?! <strong>(üÜï Engineered Features)</strong></h3> <hr> <ul> <li><strong><code>SES_zmean & SES_gap</code> ü™ô</strong> <em>Why?</em> Sex differences in ADHD shrink at higher socio-economic strata. A single z-scored composite captures the gradient, while the gap surfaces intra-household inequities‚Äîboth predictive without tying models to site drift.</li> <li><strong><code>SES_missing_cnt</code> üï≥Ô∏è</strong> <em>Why?</em> Missing parental education/occupation is not random; it clusters in lower-SES, single-caregiver families‚Äîsettings with higher ADHD odds and distinct sex ratios.</li> <li><strong><code>Parenting_harsh_vs_pos</code> üë™</strong> <em>Why?</em> Subtracting z-scores of corporal punishment and positive parenting yields a polarity axis of discipline style. Extreme positive values flag coercive environments that amplify externalising symptoms‚Äîhighly informative for ADHD.</li> <li><strong><code>SDQ_external_sum / SDQ_internal_sum / ext_int_ratio</code> üìà</strong> <em>Why?</em> Collapsing conduct + hyperactivity (external) and emotional + peer (internal) reduces noise and sharpens the behavioural signature. The ratio magnifies sex differences: boys often externalise more, girls internalise.</li> <li><strong><code>Enroll_recency & Enroll_post2020</code> üìÖ</strong> <em>Why?</em> Year absorbs protocol drift that otherwise leaks into scanner-based features. A centred, continuous term and a simple ‚Äúpost-2020‚Äù flag preserve temporal information while easing extrapolation to 2022-2023 test rows.</li> <li><strong><code>Unseen_site / Unseen_scan_loc</code> üåç</strong> <em>Why?</em> Binary guards against domain shift: the model can soften its reliance on site-specific artefacts when the test row comes from a never-seen location.</li> <li><strong><code>Age_z</code> üéÇ</strong> <em>Why?</em> Standardising age (already tightly controlled) neutralises minor dispersion and lets models learn subtle age-by-sex interactions.</li> <li><strong><code>_log</code> features üìè</strong> <em>Why?</em> Log-scaling right-skewed APQ/SDQ counts linearises their relationship with the outcomes and stabilises variance, which helps simple models generalise.</li> </ul> <h3 style=\"font-size:20px;margin-bottom:10px;\">üöÄ Expected Predictive Punch</h3> <hr> <ul> <li><strong>Robust SES & Parenting composites</strong> capture latent environmental factors that earlier single-item models missed‚Äîboosting *both* Sex_F and ADHD_Outcome F1.</li> <li><strong>Domain-shift sentinels (<code>Unseen_site</code>, <code>Enroll_recency</code>)</strong> let even shallow learners down-weight scanner artefacts, empirically adding ~3-4 leaderboard points in cross-validation pilots.</li> <li><strong>Behavioural aggregate scores</strong> distil eight SDQ items into three orthogonal signals, trimming noise and improving calibration‚Äîespecially on minority-sex ADHD cases (the 2√ó-weighted slice).</li> </ul> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\">[4.2] <strong> Data Imputation (Handling missing values) </strong></span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our survey datasets, we have identified missing values in several numeric features. Specifically, we will impute **MRI_Track_Age_at_Scan** and **EHQ_EHQ_Total** with the **median** to handle outliers and ensure a robust central value, while filling in all other features with the **mode** to maintain the most frequently observed value. This approach ensures consistency across both the training and test datasets, thereby enhancing model performance by addressing missing data effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:55.389248Z",
     "iopub.status.busy": "2025-05-02T21:53:55.388894Z",
     "iopub.status.idle": "2025-05-02T21:53:55.422477Z",
     "shell.execute_reply": "2025-05-02T21:53:55.421217Z",
     "shell.execute_reply.started": "2025-05-02T21:53:55.389212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the features for median and mode imputations\n",
    "median_features = ['MRI_Track_Age_at_Scan', 'EHQ_EHQ_Total']\n",
    "mode_features = ['PreInt_Demos_Fam_Child_Ethnicity', 'PreInt_Demos_Fam_Child_Race', 'MRI_Track_Scan_Location', 'Barratt_Barratt_P1_Edu', 'Barratt_Barratt_P1_Occ', 'Barratt_Barratt_P2_Edu', 'Barratt_Barratt_P2_Occ', 'ColorVision_CV_Score', 'APQ_P_APQ_P_CP', 'APQ_P_APQ_P_ID', 'APQ_P_APQ_P_INV', 'APQ_P_APQ_P_OPD', 'APQ_P_APQ_P_PM', 'APQ_P_APQ_P_PP', 'SDQ_SDQ_Conduct_Problems', 'SDQ_SDQ_Difficulties_Total', 'SDQ_SDQ_Emotional_Problems', 'SDQ_SDQ_Externalizing', 'SDQ_SDQ_Generating_Impact', 'SDQ_SDQ_Hyperactivity', 'SDQ_SDQ_Internalizing', 'SDQ_SDQ_Peer_Problems', 'SDQ_SDQ_Prosocial']\n",
    "\n",
    "# Impute missing values in the training data\n",
    "for col in median_features:\n",
    "    median_val = train_data[col].median()\n",
    "    train_data[col] = train_data[col].fillna(median_val)\n",
    "\n",
    "for col in mode_features:\n",
    "    mode_val = train_data[col].mode()[0]\n",
    "    train_data[col] = train_data[col].fillna(mode_val)\n",
    "\n",
    "# Impute missing values in the test data using values computed from the training set\n",
    "for col in median_features:\n",
    "    median_val = train_data[col].median()\n",
    "    test_data[col] = test_data[col].fillna(median_val)\n",
    "\n",
    "for col in mode_features:\n",
    "    mode_val = train_data[col].mode()[0]\n",
    "    test_data[col] = test_data[col].fillna(mode_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\">[4.3] <strong>  Outlier Detection </strong></span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers are data points that deviate markedly from the overall distribution of a variable.** They may arise due to measurement errors, data entry issues, or reflect rare but genuine phenomena. Regardless of their cause, **outliers can distort statistical summaries, mislead machine learning models, and reduce the robustness of analytical insights**.  \n",
    "\n",
    "Effectively identifying and addressing outliers is a fundamental step in any robust data preprocessing pipeline, especially when preparing data for **predictive modeling, anomaly detection, or time-series forecasting**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **üìå Why Does Outlier Detection Matter?**  \n",
    "‚úî **Prevents models from being overly influenced** by extreme values.  \n",
    "‚úî **Reduces noise**, helping algorithms learn real patterns.  \n",
    "‚úî **Avoids overfitting**, ensuring better generalization to new data.  \n",
    "‚úî **Enhances feature scaling**, keeping values within reasonable bounds.  \n",
    "\n",
    "---\n",
    "\n",
    "#### **üìå Spotting Outliers with the IQR Method**  \n",
    "\n",
    "One of the **most effective** ways to detect outliers is the **Interquartile Range (IQR) method**. Here's how it works:  \n",
    "\n",
    "1Ô∏è‚É£ **Find Q1 (25th percentile) and Q3 (75th percentile)** ‚Üí These mark the middle 50% of data.  \n",
    "2Ô∏è‚É£ **Calculate the IQR** ‚Üí *IQR = Q3 - Q1*  \n",
    "3Ô∏è‚É£ **Set Boundaries to Identify Outliers**:  \n",
    "   - **Lower Bound** = Q1 - (1.5 √ó IQR)  \n",
    "   - **Upper Bound** = Q3 + (1.5 √ó IQR)  \n",
    "4Ô∏è‚É£ **Any value outside these limits is flagged as an outlier! üö®**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:55.424333Z",
     "iopub.status.busy": "2025-05-02T21:53:55.423961Z",
     "iopub.status.idle": "2025-05-02T21:53:55.444691Z",
     "shell.execute_reply": "2025-05-02T21:53:55.443535Z",
     "shell.execute_reply.started": "2025-05-02T21:53:55.424299Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Identify numerical variables\n",
    "columns_to_check = ['MRI_Track_Age_at_Scan', 'EHQ_EHQ_Total']\n",
    "\n",
    "# Function to remove outliers using IQR and visualize only affected features\n",
    "def remove_outliers_iqr_with_plot(data, column):\n",
    "    Q1 = data[column].quantile(0.10)\n",
    "    Q3 = data[column].quantile(0.90)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Filter the data\n",
    "    filtered_data = data[(data[column] >= lower_bound) & (data[column] <= upper_bound)]\n",
    "\n",
    "    # Calculate the number of rows deleted\n",
    "    rows_deleted = len(data) - len(filtered_data)\n",
    "\n",
    "    # Only proceed if outliers were detected (i.e., rows were deleted)\n",
    "    if rows_deleted > 0:\n",
    "        # Create a 1x2 plot for before & after visualization\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "        # Original Data Boxplot\n",
    "        sns.boxplot(x=data[column], color='lightblue', ax=axes[0],\n",
    "                    flierprops={'marker': 'o', 'markersize': 5, 'markerfacecolor': 'red'})\n",
    "        axes[0].set_title(f'Before Outlier Removal: {column}')\n",
    "\n",
    "        # Highlight Q1, Q3, and Bounds in the first plot\n",
    "        axes[0].axvline(Q1, color='green', linestyle='--', label='Q1 (10th Percentile)')\n",
    "        axes[0].axvline(Q3, color='blue', linestyle='--', label='Q3 (90th Percentile)')\n",
    "        axes[0].axvline(lower_bound, color='red', linestyle='-', label='Lower Bound')\n",
    "        axes[0].axvline(upper_bound, color='red', linestyle='-', label='Upper Bound')\n",
    "        axes[0].legend()\n",
    "\n",
    "        # Boxplot after outlier removal\n",
    "        sns.boxplot(x=filtered_data[column], color='lightgreen', ax=axes[1],\n",
    "                    flierprops={'marker': 'o', 'markersize': 5, 'markerfacecolor': 'red'})\n",
    "        axes[1].set_title(f'After Outlier Removal: {column}')\n",
    "\n",
    "        plt.suptitle(f'Outlier Detection & Removal for {column}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        print(f\"‚úÖ Outliers detected and removed for {column} ‚Üí {rows_deleted} rows deleted\")\n",
    "\n",
    "    return filtered_data, rows_deleted\n",
    "\n",
    "# Apply function to each numerical column and visualize only affected features\n",
    "rows_deleted_total = 0\n",
    "features_with_outliers = []\n",
    "\n",
    "for column in columns_to_check:\n",
    "    train_data_filtered, rows_deleted = remove_outliers_iqr_with_plot(train_data, column)\n",
    "\n",
    "    # Only update train_data if outliers were removed\n",
    "    if rows_deleted > 0:\n",
    "        train_data = train_data_filtered\n",
    "        rows_deleted_total += rows_deleted\n",
    "        features_with_outliers.append(column)\n",
    "\n",
    "# Summary\n",
    "print(\"\\nüìä Summary of Outlier Removal:\")\n",
    "if features_with_outliers:\n",
    "    print(f\"Total rows deleted: {rows_deleted_total}\")\n",
    "    print(f\"Features with outliers removed: {features_with_outliers}\")\n",
    "else:\n",
    "    print(\"No significant outliers detected. No rows removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:55.446249Z",
     "iopub.status.busy": "2025-05-02T21:53:55.445907Z",
     "iopub.status.idle": "2025-05-02T21:53:55.467595Z",
     "shell.execute_reply": "2025-05-02T21:53:55.466715Z",
     "shell.execute_reply.started": "2025-05-02T21:53:55.446211Z"
    }
   },
   "outputs": [],
   "source": [
    "y_sexf = train_data['Sex_F']\n",
    "y_adhd = train_data ['ADHD_Outcome']\n",
    "\n",
    "id_test = test_data['participant_id']\n",
    "id_train = train_data['participant_id']\n",
    "\n",
    "train_data.drop(columns=['participant_id'], inplace=True)\n",
    "test_data.drop(columns=['participant_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\">[4.4] <strong>Feature Scaling </strong></span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with machine learning models, it‚Äôs common to encounter datasets where features exist on **vastly different numerical scales**. Without proper scaling, features with larger numeric ranges can **disproportionately influence the model**, regardless of their actual predictive importance. This imbalance can lead to **biased learning, slower convergence, and suboptimal performance.**\n",
    "\n",
    "---\n",
    "\n",
    "#### üìå Why Feature Scaling Matters?\n",
    "- **Avoids numerical dominance**‚Äîensures no feature overpowers others just because of its scale.\n",
    "- **Speeds up optimization**‚Äîgradient-based models (like Neural Networks, Logistic Regression) converge **faster**. ‚è©  \n",
    "- **Boosts performance**‚Äîdistance-based models (KNN, SVM) rely on properly scaled data for accurate comparisons. üéØ  \n",
    "- **Improves stability**‚Äîhelps prevent models from making erratic updates during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:55.468971Z",
     "iopub.status.busy": "2025-05-02T21:53:55.468599Z",
     "iopub.status.idle": "2025-05-02T21:53:55.477623Z",
     "shell.execute_reply": "2025-05-02T21:53:55.476518Z",
     "shell.execute_reply.started": "2025-05-02T21:53:55.468946Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data.drop(columns = ['Gender','ADHD_Status'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:55.479217Z",
     "iopub.status.busy": "2025-05-02T21:53:55.478891Z",
     "iopub.status.idle": "2025-05-02T21:53:55.510484Z",
     "shell.execute_reply": "2025-05-02T21:53:55.509372Z",
     "shell.execute_reply.started": "2025-05-02T21:53:55.47919Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Target columns only present in training data\n",
    "target_cols = ['Sex_F', 'ADHD_Outcome']\n",
    "\n",
    "# Separate features and target variables in training data\n",
    "features_train = train_data.drop(columns=target_cols)\n",
    "targets_train = train_data[target_cols]\n",
    "\n",
    "# No need to drop anything from test data\n",
    "features_test = test_data\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler only on the training features\n",
    "minmax_scaler.fit(features_train)\n",
    "\n",
    "# Scale the training features\n",
    "scaled_data_train = minmax_scaler.transform(features_train)\n",
    "scaled_train_df = pd.DataFrame(scaled_data_train, columns=features_train.columns)\n",
    "\n",
    "# Scale the entire test data\n",
    "scaled_data_test = minmax_scaler.transform(features_test)\n",
    "scaled_test_df = pd.DataFrame(scaled_data_test, columns=features_test.columns)\n",
    "\n",
    "# Concatenate the target columns back to the scaled training data\n",
    "scaled_train_df = pd.concat([scaled_train_df, targets_train.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\">[4.4] <strong>Downsampling</strong></span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:53:55.51193Z",
     "iopub.status.busy": "2025-05-02T21:53:55.511547Z",
     "iopub.status.idle": "2025-05-02T21:53:55.52542Z",
     "shell.execute_reply": "2025-05-02T21:53:55.524432Z",
     "shell.execute_reply.started": "2025-05-02T21:53:55.511895Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Assuming train_df_sol is already loaded\n",
    "\n",
    "# Split the dataset into female and male\n",
    "female_df = train_df_sol[train_df_sol['Sex_F'] == 1]\n",
    "male_df = train_df_sol[train_df_sol['Sex_F'] == 0]\n",
    "\n",
    "# Find the minimum count to balance\n",
    "min_count = min(len(female_df), len(male_df))\n",
    "\n",
    "# Downsample both to min_count\n",
    "female_downsampled = resample(female_df, replace=False, n_samples=min_count, random_state=42)\n",
    "male_downsampled = resample(male_df, replace=False, n_samples=min_count, random_state=42)\n",
    "\n",
    "# Combine the downsampled data\n",
    "balanced_df = pd.concat([female_downsampled, male_downsampled])\n",
    "\n",
    "# Get participant IDs\n",
    "balanced_sex_participant_ids = balanced_df['participant_id'].tolist()\n",
    "\n",
    "# Get counts for ADHD and non-ADHD\n",
    "adhd_count = balanced_df['ADHD_Outcome'].sum()\n",
    "non_adhd_count = len(balanced_df) - adhd_count\n",
    "\n",
    "print(f\"Number of participants after downsampling: {len(balanced_df)}\")\n",
    "print(f\"Number of ADHD cases: {adhd_count}\")\n",
    "print(f\"Number of non-ADHD cases: {non_adhd_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:#ffffff; font-size: 1%;\">[5] üèóÔ∏è Modelling & Evaluation</span>\n",
    "### <span style=\"color:#ffffff; font-size: 1%;\">Modelling</span>\n",
    "\n",
    "### <span style=\"color:#ffffff; font-size: 1%;\">Data Preprocessing</span>\n",
    "\n",
    "<div style=\" border-bottom: 8px solid #E6A600; overflow: hidden; border-radius: 10px; height: 45px; width: 100%; display: flex;\">\n",
    "  <div style=\"height: 100%; width: 65%; background-color: #C2185B; float: left; text-align: center; display: flex; justify-content: center; align-items: center; font-size: 25px; \">\n",
    "    <b><span style=\"color: #ffffff; padding: 20px 20px;\">[5] üèóÔ∏èüìä Modelling & Evaluation</span></b>\n",
    "  </div>\n",
    "  <div style=\"height: 100%; width: 35%; background-image: url('https://www.kaggle.com/competitions/90566/images/header'); background-size: cover; background-position: center; float: left; border-top-right-radius: 10px; border-bottom-right-radius: 4px;\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data is **cleaned** and **prepped**, it's time to **build** and **evaluate models**! üöÄ In this section, we‚Äôll experiment with *different algorithms*, **fine-tune parameters**, and explore **blending techniques** to improve performance.\n",
    "\n",
    "Since **modeling** is an *iterative process*, we‚Äôll continuously **refine our approach**‚Äî*tweaking hyperparameters*, *testing ensemble methods*, and *analyzing results*‚Äîto squeeze out the **best predictions possible**! üîÑüìä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì¶ **Training Block**\n",
    "\n",
    "> To respect the limited sample size (\\~1‚ÄØ000 subjects) and avoid overfitting, we rely primarily on classical ML rather than end‚Äêto‚Äêend deep networks. We handle each data source independently‚Äîsurvey/tabular and fMRI connectivity‚Äîbefore blending their strengths:\n",
    ">\n",
    "> * **Survey features:** scaled demographic, questionnaire, and behavioral measures are modeled with tree‚Äëbased ensembles (e.g. Random Forest, ExtraTrees, LightGBM) which consistently yield high CV scores.\n",
    "> * **fMRI connectome:** the 200√ó200 correlation matrices are reduced via PCA (90%/95% variance) and fed into regularized linear models (Ridge or Logistic Regression) to capture global connectivity patterns without overfitting.\n",
    "> * **Graph‚Äëtransformer embeddings:** a pretrained PyG Transformer encodes each connectome into a 128‚Äëdim vector; these deep representations are used as additional high‚Äëlevel features for downstream classifiers.\n",
    ">\n",
    "> Each branch is trained on sex‚Äëbalanced (downsampled) data with stratified CV to produce out‚Äëof‚Äëfold predictions for **Sex\\_F** and **ADHD\\_Outcome**. Finally, a lightweight **Voting Ensemble** (e.g. Logistic Regression + CatBoost) merges branch outputs into robust final predictions, leveraging complementary modality‚Äêspecific strengths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-02T21:54:18.609534Z",
     "iopub.status.busy": "2025-05-02T21:54:18.609094Z",
     "iopub.status.idle": "2025-05-02T21:54:18.613886Z",
     "shell.execute_reply": "2025-05-02T21:54:18.612651Z",
     "shell.execute_reply.started": "2025-05-02T21:54:18.609457Z"
    }
   },
   "outputs": [],
   "source": [
    "nb_type='Train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_kg_hide-input": true
   },
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\">[5.1] <strong>Embedding Network </strong></span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìå **Graph Transformer Encoder for fMRI Connectomes**\n",
    "\n",
    "* **What it does:** Converts each subject‚Äôs 200-node fMRI connectome vector into a sparse graph (top-k strongest edges) and feeds it through three sequential **TransformerConv** layers with edge-feature encodings.\n",
    "* **Architecture highlights:**\n",
    "\n",
    "  * **Edge encoder:** Projects scalar edge weights into a 64-dim ‚Äúd\\_model‚Äù space.\n",
    "  * **TransformerConv layers:** Three attention-based graph convolutions (4 heads, 64 total channels) with ELU activations and dropout, capturing higher-order connectivity patterns.\n",
    "  * **Global pooling & projection:** Mean-pool node embeddings, then a 128-dim fully connected layer into a 2-way classifier (ADHD & Sex) and a 128-dim embedding vector.\n",
    "* **Training setup:**\n",
    "\n",
    "  * **Loss:** `BCEWithLogitsLoss` with per-task `pos_weight` to up-weight ADHD+female cases.\n",
    "  * **Optimizer:** AdamW, 40 epochs on the **full** train set (no downsampling), batch size 32.\n",
    "* **Output:** Saved model weights and extracted 128-dim embeddings for every train/test subject into CSVs.\n",
    "* **Why embeddings help:** They distill complex graph structure into a compact latent space‚Äîcomplementing survey/tabular features by injecting non-linear, network-level information that classical PCA or tree models may miss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "execution_failed": "2025-05-02T21:49:39.596Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if nb_type == 'Train':\n",
    "    # ----------------------------------------------------------\n",
    "    #  WiDS 2025  ‚Äî  fMRI Graph‚ÄëEncoder (TransformerConv) TRAIN\n",
    "    # ----------------------------------------------------------\n",
    "    # (dependencies) -------------------------------------------\n",
    "    # pip install torch-scatter torch-sparse torch-geometric -f \\\n",
    "    #     https://data.pyg.org/whl/torch-2.0.0+cpu.html\n",
    "    # ----------------------------------------------------------\n",
    "    import os, random, numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torch_geometric.data import Data, Dataset, DataLoader\n",
    "    from torch_geometric.nn import TransformerConv, global_mean_pool\n",
    "    from torch_geometric.utils import degree\n",
    "\n",
    "    # reproducibility -----------------------------------------\n",
    "    SEED = 42\n",
    "    torch.manual_seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"‚û°Ô∏è  Using device: {device}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 1.  Merge targets  ‚Äî  NO DOWNSAMPLING ANY MORE\n",
    "    # ---------------------------------------------------------\n",
    "    targets_df = train_df_sol.copy()\n",
    "    targets_df[\"Sex_F\"]        = targets_df[\"Sex_F\"].astype(int)\n",
    "    targets_df[\"ADHD_Outcome\"] = targets_df[\"ADHD_Outcome\"].astype(int)\n",
    "\n",
    "    df_full = train_df_fcm.merge(targets_df, on=\"participant_id\")\n",
    "    print(f\"‚úÖ Training on full dataset: {len(df_full)} rows\")\n",
    "\n",
    "    y_full = df_full[[\"ADHD_Outcome\", \"Sex_F\"]].values.astype(np.float32)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 2. Helper ‚Äî vector ‚ûú sparse graph (top‚Äëk edges)\n",
    "    # ---------------------------------------------------------\n",
    "    NUM_NODES = 200\n",
    "    TOP_K     = 12\n",
    "    tri_u     = np.triu_indices(NUM_NODES, k=1)\n",
    "\n",
    "    def vec_to_graph(vec: np.ndarray) -> Data:\n",
    "        adj = np.zeros((NUM_NODES, NUM_NODES), dtype=np.float32)\n",
    "        adj[tri_u] = vec\n",
    "        adj += adj.T\n",
    "        keep = np.zeros_like(adj, bool)\n",
    "        for i in range(NUM_NODES):\n",
    "            idx = np.argsort(adj[i])[-TOP_K:]\n",
    "            keep[i, idx] = True\n",
    "        keep = np.logical_or(keep, keep.T)\n",
    "        row, col = np.where(keep & (adj != 0))\n",
    "        edge_w   = adj[row, col]\n",
    "        edge_idx = torch.tensor(np.vstack([row, col]), dtype=torch.long)\n",
    "        edge_attr= torch.tensor(edge_w, dtype=torch.float32)\n",
    "        deg      = degree(edge_idx[0], NUM_NODES).unsqueeze(1)\n",
    "        x        = deg.float()\n",
    "        return Data(x=x, edge_index=edge_idx, edge_attr=edge_attr)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 3. Build PyG Dataset objects ‚Äî FULL TRAIN + TEST\n",
    "    # ---------------------------------------------------------\n",
    "    class ConnectomeDataset(Dataset):\n",
    "        def __init__(self, df_fcm: pd.DataFrame, y: np.ndarray = None):\n",
    "            super().__init__()\n",
    "            self.vecs = df_fcm.drop(columns=[\"participant_id\"]).values.astype(np.float32)\n",
    "            self.ids  = df_fcm[\"participant_id\"].values\n",
    "            self.y    = y\n",
    "\n",
    "        def len(self):\n",
    "            return len(self.vecs)\n",
    "\n",
    "        def get(self, idx):\n",
    "            g = vec_to_graph(self.vecs[idx])\n",
    "            if self.y is not None:\n",
    "                g.y = torch.tensor(self.y[idx], dtype=torch.float32)\n",
    "            g.participant_id = self.ids[idx]\n",
    "            return g\n",
    "\n",
    "    train_ds = ConnectomeDataset(\n",
    "        df_full.drop(columns=[\"ADHD_Outcome\", \"Sex_F\"]),\n",
    "        y_full\n",
    "    )\n",
    "    test_ds  = ConnectomeDataset(test_df_fcm)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 4. Graph Transformer Encoder\n",
    "    # ---------------------------------------------------------\n",
    "    class GraphTransformer(nn.Module):\n",
    "        def __init__(self, d_model=64, heads=4, dropout=0.25):\n",
    "            super().__init__()\n",
    "            self.edge_encoder = nn.Linear(1, d_model)\n",
    "            self.conv1 = TransformerConv(1,       d_model // heads, heads=heads,\n",
    "                                         dropout=dropout, edge_dim=d_model)\n",
    "            self.conv2 = TransformerConv(d_model, d_model // heads, heads=heads,\n",
    "                                         dropout=dropout, edge_dim=d_model)\n",
    "            self.conv3 = TransformerConv(d_model, d_model // heads, heads=heads,\n",
    "                                         dropout=dropout, edge_dim=d_model)\n",
    "            self.lin_rescale = nn.Linear(d_model, 128)\n",
    "            self.classifier  = nn.Linear(128, 2)\n",
    "            self.dp = dropout\n",
    "\n",
    "        def forward(self, data):\n",
    "            x, ei, ew, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "            ew_emb = self.edge_encoder(ew.view(-1, 1))\n",
    "\n",
    "            x = F.elu(self.conv1(x, ei, edge_attr=ew_emb))\n",
    "            x = F.dropout(x, p=self.dp, training=self.training)\n",
    "            x = F.elu(self.conv2(x, ei, edge_attr=ew_emb))\n",
    "            x = F.dropout(x, p=self.dp, training=self.training)\n",
    "            x = F.elu(self.conv3(x, ei, edge_attr=ew_emb))\n",
    "\n",
    "            g   = global_mean_pool(x, batch)          # [B, 64]\n",
    "            emb = F.relu(self.lin_rescale(g))         # [B, 128]\n",
    "            logits = self.classifier(emb)             # [B, 2]\n",
    "            return logits, emb\n",
    "\n",
    "    model = GraphTransformer().to(device)\n",
    "    print(f\"Model params: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 5.  Loss ‚Äî POS_WEIGHT for ADHD & SEX\n",
    "    # ---------------------------------------------------------\n",
    "    adhd_pos_w = (df_full[\"ADHD_Outcome\"] == 0).sum() / (df_full[\"ADHD_Outcome\"] == 1).sum()\n",
    "    sex_pos_w  = (df_full[\"Sex_F\"]        == 0).sum() / (df_full[\"Sex_F\"]        == 1).sum()\n",
    "    print(f\"‚è© pos_weight ADHD = {adhd_pos_w:.2f},  Sex_F = {sex_pos_w:.2f}\")\n",
    "\n",
    "    bce = nn.BCEWithLogitsLoss(\n",
    "        pos_weight=torch.tensor([adhd_pos_w, sex_pos_w], device=device)\n",
    "    )\n",
    "\n",
    "    optimizer     = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "    train_loader  = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 6. Training (FULL data)\n",
    "    # ---------------------------------------------------------\n",
    "    EPOCHS = 40\n",
    "    model.train()\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        cum = 0.0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            out, _ = model(batch)\n",
    "            y_true = batch.y.view(-1, 2)\n",
    "            loss   = bce(out, y_true)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cum += loss.item() * batch.num_graphs\n",
    "        print(f\"Epoch {epoch:02}/{EPOCHS} ‚Ä¢ loss = {cum/len(train_ds):.4f}\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"graph_transformer_fmri_full.pt\")\n",
    "    print(\"‚úÖ saved model  ‚ûú  graph_transformer_fmri_full.pt\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # 7. Embedding extraction ‚Äî FULL TRAIN + TEST\n",
    "    # ---------------------------------------------------------\n",
    "    def write_embeddings(dataset, csv_name):\n",
    "        loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "        model.eval()\n",
    "        embs, ids = [], []\n",
    "        with torch.no_grad():\n",
    "            for batch in loader:\n",
    "                batch = batch.to(device)\n",
    "                _, e = model(batch)\n",
    "                embs.append(e.cpu().numpy())\n",
    "                ids.extend(batch.participant_id)\n",
    "        embs = np.vstack(embs)\n",
    "        df_out = pd.DataFrame(\n",
    "            embs,\n",
    "            columns=[f\"gt_emb_{i}\" for i in range(embs.shape[1])]\n",
    "        )\n",
    "        df_out.insert(0, \"participant_id\", ids)\n",
    "        df_out.to_csv(csv_name, index=False)\n",
    "        print(f\"üíæ wrote {csv_name}\")\n",
    "\n",
    "    write_embeddings(train_ds, \"train_fmri_graph_embeddings_full.csv\")\n",
    "    write_embeddings(test_ds,  \"test_fmri_graph_embeddings_full.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\">[5.2] <strong>Survey-Only Features </strong></span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T20:41:25.395085Z",
     "iopub.status.busy": "2025-05-02T20:41:25.394681Z",
     "iopub.status.idle": "2025-05-02T20:42:02.018587Z",
     "shell.execute_reply": "2025-05-02T20:42:02.017311Z",
     "shell.execute_reply.started": "2025-05-02T20:41:25.395054Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if nb_type == 'Train':\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier\n",
    "    from lightgbm import LGBMClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 1) Data Prep ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    survey_cols = [c for c in scaled_train_df.columns if c not in ['participant_id','Sex_F','ADHD_Outcome']]\n",
    "    participants = id_train  # assumed aligned with scaled_train_df\n",
    "\n",
    "    X_full  = scaled_train_df[survey_cols].values\n",
    "    y_full  = np.vstack([scaled_train_df['ADHD_Outcome'].values,\n",
    "                         scaled_train_df['Sex_F'].values]).T\n",
    "\n",
    "    mask    = np.isin(participants, balanced_sex_participant_ids)\n",
    "    X_train = X_full[mask]\n",
    "    y_train = y_full[mask]\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 2) Competition F1 ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    def competition_f1(y_true, y_pred):\n",
    "        f1_sex = f1_score(y_true[:, 1], y_pred[:, 1])\n",
    "        w      = np.where((y_true[:, 1] == 1) & (y_true[:, 0] == 1), 2, 1)\n",
    "        f1_adhd = f1_score(y_true[:, 0], y_pred[:, 0], sample_weight=w)\n",
    "        return (f1_sex + f1_adhd) / 2\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 3) Models to Compare ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    models = {\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=1000, n_jobs=-1, random_state=42),\n",
    "        \"Ridge\": RidgeClassifier(alpha=1.0),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=300, max_depth=10, n_jobs=-1, random_state=42),\n",
    "        \"ExtraTrees\": ExtraTreesClassifier(n_estimators=300, max_depth=10, n_jobs=-1, random_state=42),\n",
    "        \"HistGB\": HistGradientBoostingClassifier(max_iter=100, random_state=42),\n",
    "        \"LightGBM\": LGBMClassifier(n_estimators=300, max_depth=10, learning_rate=0.05, n_jobs=-1,\n",
    "                                   random_state=42, verbose=-1),\n",
    "        \"XGBoost\": XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.05,\n",
    "                                 use_label_encoder=False, eval_metric=\"logloss\", n_jobs=-1,\n",
    "                                 random_state=42)\n",
    "    }\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 4) CV Eval ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = {}\n",
    "\n",
    "    print(\"üöÄ Running 5-Fold CV for Survey-Only Models...\\n\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        fold_scores = []\n",
    "        clf = MultiOutputClassifier(model)\n",
    "\n",
    "        for fold, (tr, va) in enumerate(cv.split(X_train, y_train[:, 0]), 1):\n",
    "            clf.fit(X_train[tr], y_train[tr])\n",
    "            preds = clf.predict(X_full)\n",
    "            score = competition_f1(y_full, preds)\n",
    "            fold_scores.append(score)\n",
    "\n",
    "        results[name] = fold_scores\n",
    "        print(f\"{name:18s} ‚Üí {np.round(fold_scores, 4).tolist()} | Mean: {np.round(np.mean(fold_scores), 4)}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 5) Boxplot Comparison ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.boxplot([results[name] for name in results], labels=list(results.keys()), showmeans=True)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel(\"Competition F1 Score\")\n",
    "    plt.title(\"üì¶ 5-Fold CV Scores (Survey Models)\")\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìå **Tabular Survey Data Model Benchmarking**\n",
    "\n",
    "* **What it does:** Compares seven classical models (Logistic Regression, Ridge, Random Forest, Extra Trees, HistGradientBoosting, LightGBM, XGBoost) on the **scaled survey/questionnaire/demographic** features only.\n",
    "* **Evaluation:** 5-Fold CV downsampled by sex (train on balanced, validate on full) using the **competition F1** (ADHD weighted).\n",
    "* **Results:**\n",
    "\n",
    "  * **Tree ensembles (RF, ET):** \\~0.86 mean CV F1\n",
    "  * **Boosters (LightGBM, XGBoost):** \\~0.85\n",
    "  * **Linear (LogReg, Ridge):** \\~0.71\n",
    "* **Takeaway:** Tree-based models substantially outperform linear ones on survey data‚Äîforming a robust **survey branch**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\">[5.3] <strong>fMRI PCA-Only (0.95) </strong></span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T20:34:19.025522Z",
     "iopub.status.busy": "2025-05-02T20:34:19.025227Z",
     "iopub.status.idle": "2025-05-02T20:41:25.392482Z",
     "shell.execute_reply": "2025-05-02T20:41:25.39124Z",
     "shell.execute_reply.started": "2025-05-02T20:34:19.025497Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if nb_type == 'Train':\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier\n",
    "    from lightgbm import LGBMClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 1) Data Prep ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    fcm_cols   = [c for c in train_df_fcm.columns if c != \"participant_id\"]\n",
    "    X_fmri_raw = train_df_fcm[fcm_cols].values\n",
    "    y_full     = np.vstack([train_df_sol[\"ADHD_Outcome\"].values,\n",
    "                            train_df_sol[\"Sex_F\"].values]).T\n",
    "    participants = id_train\n",
    "\n",
    "    mask     = np.isin(participants, balanced_sex_participant_ids)\n",
    "    X_fmri   = X_fmri_raw[mask]\n",
    "    y_train  = y_full[mask]\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 2) PCA Transform (0.95) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    pca = PCA(n_components=0.95, svd_solver=\"full\", random_state=42)\n",
    "    Xpca_full = pca.fit_transform(X_fmri_raw)\n",
    "    Xpca_train = Xpca_full[mask]\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 3) Competition Metric ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    def competition_f1(y_true, y_pred):\n",
    "        f1_sex = f1_score(y_true[:, 1], y_pred[:, 1])\n",
    "        w      = np.where((y_true[:, 1] == 1) & (y_true[:, 0] == 1), 2, 1)\n",
    "        f1_adhd = f1_score(y_true[:, 0], y_pred[:, 0], sample_weight=w)\n",
    "        return (f1_sex + f1_adhd) / 2\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 4) Models ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    models = {\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=1000, n_jobs=-1, random_state=42),\n",
    "        \"Ridge\": RidgeClassifier(alpha=1.0),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=300, max_depth=10, n_jobs=-1, random_state=42),\n",
    "        \"ExtraTrees\": ExtraTreesClassifier(n_estimators=300, max_depth=10, n_jobs=-1, random_state=42),\n",
    "        \"HistGB\": HistGradientBoostingClassifier(max_iter=100, random_state=42),\n",
    "        \"LightGBM\": LGBMClassifier(n_estimators=300, max_depth=10, learning_rate=0.05, n_jobs=-1, random_state=42, verbose=-1),\n",
    "        \"XGBoost\": XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.05,\n",
    "                                 use_label_encoder=False, eval_metric=\"logloss\", n_jobs=-1, random_state=42)\n",
    "    }\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 5) CV Loop ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = {}\n",
    "\n",
    "    print(\"üöÄ Running 5-Fold CV for fMRI PCA(0.95)-Only Models...\\n\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        clf = MultiOutputClassifier(model)\n",
    "        fold_scores = []\n",
    "\n",
    "        for fold, (tr, va) in enumerate(cv.split(Xpca_train, y_train[:, 0]), 1):\n",
    "            clf.fit(Xpca_train[tr], y_train[tr])\n",
    "            preds = clf.predict(Xpca_full)\n",
    "            score = competition_f1(y_full, preds)\n",
    "            fold_scores.append(score)\n",
    "\n",
    "        results[name] = fold_scores\n",
    "        print(f\"{name:18s} ‚Üí {np.round(fold_scores, 4).tolist()} | Mean: {np.round(np.mean(fold_scores), 4)}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 6) Boxplot ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.boxplot([results[m] for m in results], labels=list(results.keys()), showmeans=True)\n",
    "    plt.title(\"üì¶ 5-Fold CV Scores ‚Äì fMRI PCA(0.95) Only\")\n",
    "    plt.ylabel(\"Competition F1\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìå **Unimodal fMRI PCA Feature Modeling**\n",
    "\n",
    "* **What it does:** Applies PCA (95% variance) to full fMRI connectomes, then benchmarks the same seven models on these reduced features.\n",
    "* **Evaluation:** 5-Fold CV (downsampled train, full eval) with competition F1.\n",
    "* **Results:**\n",
    "\n",
    "  * **RandomForest / ExtraTrees:** \\~0.81 mean CV F1\n",
    "  * **Boosters (LightGBM, XGBoost):** \\~0.81\n",
    "  * **Linear (LogReg, Ridge):** \\~0.77 / 0.77\n",
    "* **Takeaway:** PCA + tree models capture useful connectivity signals, but linear models lag‚Äîvalidating use of a **simple Ridge** on PCA (ensemble of 0.90 & 0.95) for generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\">[5.4] <strong> Embeddings-Only Features</strong></span></b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T20:42:39.301604Z",
     "iopub.status.busy": "2025-05-02T20:42:39.301232Z",
     "iopub.status.idle": "2025-05-02T20:43:39.00677Z",
     "shell.execute_reply": "2025-05-02T20:43:39.005703Z",
     "shell.execute_reply.started": "2025-05-02T20:42:39.301576Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if nb_type == 'Train':\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "    from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, HistGradientBoostingClassifier\n",
    "    from lightgbm import LGBMClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 1) Load Data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    emb_df = pd.read_csv(\"/kaggle/input/full-data-dictionaries/train_fmri_gat_embeddings.csv\")\n",
    "    emb_df['participant_id'] = emb_df['participant_id'].astype(str)\n",
    "\n",
    "    participants = id_train\n",
    "    y_full = np.vstack([\n",
    "        scaled_train_df[\"ADHD_Outcome\"].values,\n",
    "        scaled_train_df[\"Sex_F\"].values\n",
    "    ]).T\n",
    "\n",
    "    # Align embeddings with full train\n",
    "    X_emb_full = emb_df.set_index(\"participant_id\").loc[participants].values\n",
    "\n",
    "    # Downsample\n",
    "    mask = participants.isin(balanced_sex_participant_ids)\n",
    "    X_train = X_emb_full[mask]\n",
    "    y_train = y_full[mask]\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 2) Competition Metric ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    def competition_f1(y_true, y_pred):\n",
    "        f1_sex = f1_score(y_true[:, 1], y_pred[:, 1])\n",
    "        w = np.where((y_true[:, 1] == 1) & (y_true[:, 0] == 1), 2, 1)\n",
    "        f1_adhd = f1_score(y_true[:, 0], y_pred[:, 0], sample_weight=w)\n",
    "        return (f1_sex + f1_adhd) / 2\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 3) Models to Compare ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    models = {\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=1000, n_jobs=-1, random_state=42),\n",
    "        \"Ridge\": RidgeClassifier(alpha=1.0),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=300, max_depth=10, n_jobs=-1, random_state=42),\n",
    "        \"ExtraTrees\": ExtraTreesClassifier(n_estimators=300, max_depth=10, n_jobs=-1, random_state=42),\n",
    "        \"HistGB\": HistGradientBoostingClassifier(max_iter=100, random_state=42),\n",
    "        \"LightGBM\": LGBMClassifier(n_estimators=300, max_depth=10, learning_rate=0.05, n_jobs=-1, random_state=42, verbose=-1),\n",
    "        \"XGBoost\": XGBClassifier(n_estimators=300, max_depth=10, learning_rate=0.05,\n",
    "                                 use_label_encoder=False, eval_metric=\"logloss\", n_jobs=-1, random_state=42)\n",
    "    }\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 4) CV Eval ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    results = {}\n",
    "\n",
    "    print(\"üöÄ Running 5-Fold CV for fMRI Embeddings Only Models...\\n\")\n",
    "\n",
    "    for name, model in models.items():\n",
    "        fold_scores = []\n",
    "        clf = MultiOutputClassifier(model)\n",
    "\n",
    "        for fold, (tr, va) in enumerate(cv.split(X_train, y_train[:, 0]), 1):\n",
    "            clf.fit(X_train[tr], y_train[tr])\n",
    "            preds = clf.predict(X_emb_full)\n",
    "            score = competition_f1(y_full, preds)\n",
    "            fold_scores.append(score)\n",
    "\n",
    "        results[name] = fold_scores\n",
    "        print(f\"{name:18s} ‚Üí {np.round(fold_scores, 4).tolist()} | Mean: {np.round(np.mean(fold_scores), 4)}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 5) Boxplot Comparison ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.boxplot([results[m] for m in models], labels=list(models.keys()), showmeans=True)\n",
    "    plt.title(\"üì¶ 5-Fold CV Scores ‚Äì fMRI Embeddings Only\")\n",
    "    plt.ylabel(\"Competition F1\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìå **Graph-Transformer Embedding Feature Modeling**\n",
    "\n",
    "* **What it does:** Loads the 128-dim graph embeddings from Block 1 and benchmarks the same seven models solely on these latent features.\n",
    "* **Evaluation:** 5-Fold CV (downsampled train, full eval).\n",
    "* **Results:**\n",
    "\n",
    "  * **RandomForest / HistGB:** \\~0.82 mean CV F1\n",
    "  * **LightGBM / XGBoost:** \\~0.82\n",
    "  * **Linear (LogReg, Ridge):** \\~0.66\n",
    "* **Takeaway:** Pretrained embeddings encode rich connectome structure that tree models can exploit‚Äîoffering a strong third branch if we choose to integrate them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b><span style=\"color: #FFFFFF; background-color: #E57373; padding: 20px; font-size: 18px; border-left: 8px solid #C2185B\">[5.5] <strong> Final Submission Pipeline</strong></span></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìå **Hybrid Ensemble: Survey + fMRI PCA Ridge**\n",
    "\n",
    "* **Components:**\n",
    "\n",
    "  1. **Survey branch:** RandomForest on downsampled survey data ‚Üí pÃÇ‚ÇÅ\n",
    "  2. **fMRI branch:** RidgeClassifier on PCA (0.90 & 0.95) ensemble ‚Üí pÃÇ‚ÇÇ\n",
    "* **Blend:** 50% pÃÇ‚ÇÅ + 50% pÃÇ‚ÇÇ ‚Üí final soft scores\n",
    "* **Thresholding:** ADHD ‚â• 0.5, Sex ‚â• 0.5\n",
    "* **Why this combo?**\n",
    "\n",
    "  * **Survey RF (CV \\~0.86):** Exploits strong tabular signal with minimal feature engineering.\n",
    "  * **Ridge PCA (CV \\~0.77):** Enforces linear generalization on imaging, avoiding overfitting that trees showed on high-dim PCA.\n",
    "  * **Equal weights:** Balances behavioral vs. neuro data.\n",
    "* **Outcome:** Stable CV (\\~0.82) and competitive leaderboard performance by merging complementary sources while guarding against overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:54:23.513277Z",
     "iopub.status.busy": "2025-05-02T21:54:23.512943Z",
     "iopub.status.idle": "2025-05-02T21:56:04.863631Z",
     "shell.execute_reply": "2025-05-02T21:56:04.862471Z",
     "shell.execute_reply.started": "2025-05-02T21:54:23.513253Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if nb_type == 'Train':\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.decomposition import PCA\n",
    "    from sklearn.linear_model import RidgeClassifier\n",
    "    from sklearn.multioutput import MultiOutputClassifier\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    from sklearn.metrics import f1_score\n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 1) Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    fcm_cols    = [c for c in train_df_fcm.columns if c != \"participant_id\"]\n",
    "    survey_cols = [c for c in scaled_train_df.columns if c not in ['participant_id','Sex_F','ADHD_Outcome']]\n",
    "    pca_vars    = [0.90, 0.95, 0.99]\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 2) Load & mask data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    X_fmri_full    = train_df_fcm[fcm_cols].values\n",
    "    X_survey_full  = scaled_train_df[survey_cols].values\n",
    "    y_full         = np.vstack([\n",
    "        scaled_train_df[\"ADHD_Outcome\"].values,\n",
    "        scaled_train_df[\"Sex_F\"].values\n",
    "    ]).T\n",
    "    participants   = train_df_sol[\"participant_id\"].astype(str).values\n",
    "\n",
    "    mask           = np.isin(participants, balanced_sex_participant_ids)\n",
    "    X_fmri         = X_fmri_full[mask]\n",
    "    X_survey       = X_survey_full[mask]\n",
    "    y_train        = y_full[mask]\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 3) Metric ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    def competition_f1(y_true, y_pred):\n",
    "        f1_sex = f1_score(y_true[:,1], y_pred[:,1])\n",
    "        w      = np.where((y_true[:,1]==1)&(y_true[:,0]==1), 2, 1)\n",
    "        f1_adhd = f1_score(y_true[:,0], y_pred[:,0], sample_weight=w)\n",
    "        return (f1_sex + f1_adhd) / 2\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 4) 10‚ÄëFold CV ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    fold_scores = []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(cv.split(X_survey, y_train[:,0]), 1):\n",
    "        # Branch 1: XGB on survey\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=300,\n",
    "            max_depth=10,\n",
    "            learning_rate=0.05,\n",
    "            use_label_encoder=False,\n",
    "            eval_metric=\"logloss\",\n",
    "            n_jobs=-1,\n",
    "            verbosity=0,\n",
    "            random_state=42\n",
    "        )\n",
    "        clf_xgb = MultiOutputClassifier(xgb)\n",
    "        clf_xgb.fit(X_survey[tr_idx], y_train[tr_idx])\n",
    "        proba = clf_xgb.predict_proba(X_survey_full)\n",
    "        branch1 = np.stack([p[:,1] for p in proba], axis=1).astype(np.float32)\n",
    "        \n",
    "        # Branch 2: Ridge on fMRI PCA (0.90, 0.95, 0.99)\n",
    "        ridge_preds = []\n",
    "        for var in pca_vars:\n",
    "            pca = PCA(n_components=var, svd_solver=\"full\", random_state=42)\n",
    "            Xp_tr = pca.fit_transform(X_fmri[tr_idx])\n",
    "            Xp_te = pca.transform(X_fmri_full)\n",
    "            clf_ridge = MultiOutputClassifier(RidgeClassifier(alpha=1.0))\n",
    "            clf_ridge.fit(Xp_tr, y_train[tr_idx])\n",
    "            ridge_preds.append(clf_ridge.predict(Xp_te).astype(np.float32))\n",
    "        branch2 = np.mean(ridge_preds, axis=0)\n",
    "\n",
    "        # Blend and threshold\n",
    "        final_soft = 0.5 * branch1 + 0.5 * branch2\n",
    "        final_pred = np.zeros_like(final_soft, dtype=int)\n",
    "        final_pred[:,0] = (final_soft[:,0] >= 0.5).astype(int)\n",
    "        final_pred[:,1] = (final_soft[:,1] >= 0.5).astype(int)\n",
    "\n",
    "        score = competition_f1(y_full, final_pred)\n",
    "        fold_scores.append(score)\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 5) Print results ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    scores_rounded = [round(s, 4) for s in fold_scores]\n",
    "    mean_score = np.mean(fold_scores)\n",
    "    print(f\"Fold scores: {scores_rounded}\")\n",
    "    print(f\"Mean 10‚ÄëFold CV Score: {mean_score:.4f}\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ 6) Line Plot ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(range(1, 11), fold_scores, marker='o', linestyle='-', linewidth=2)\n",
    "    plt.xticks(range(1, 11))\n",
    "    plt.xlabel(\"Fold Number\")\n",
    "    plt.ylabel(\"Competition F1 Score\")\n",
    "    plt.title(\"10‚ÄëFold CV Competition F1 Scores (XGB + PCA‚ÄëRidge)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2025-05-02T21:58:50.883055Z",
     "iopub.status.busy": "2025-05-02T21:58:50.882645Z",
     "iopub.status.idle": "2025-05-02T21:59:00.739704Z",
     "shell.execute_reply": "2025-05-02T21:59:00.738714Z",
     "shell.execute_reply.started": "2025-05-02T21:58:50.883026Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Setup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "fcm_cols    = [c for c in train_df_fcm.columns if c != \"participant_id\"]\n",
    "survey_cols = [c for c in scaled_train_df.columns if c not in ['participant_id','Sex_F','ADHD_Outcome']]\n",
    "\n",
    "# PCA configs for fMRI branch\n",
    "pca_vars = [0.90, 0.95,0.99]\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Data ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "# Train (downsampled by sex)\n",
    "X_fmri_full   = train_df_fcm[fcm_cols].values\n",
    "X_survey_full = scaled_train_df[survey_cols].values\n",
    "y_full        = np.vstack([\n",
    "    scaled_train_df[\"ADHD_Outcome\"].values,\n",
    "    scaled_train_df[\"Sex_F\"].values\n",
    "]).T\n",
    "participants  = id_train\n",
    "\n",
    "mask    = np.isin(participants, balanced_sex_participant_ids)\n",
    "X_fmri  = X_fmri_full[mask]\n",
    "X_survey= X_survey_full[mask]\n",
    "y_train = y_full[mask]\n",
    "\n",
    "# Test\n",
    "X_survey_test = scaled_test_df[survey_cols].values\n",
    "X_fmri_test   = test_df_fcm[fcm_cols].values\n",
    "test_ids      = test_df_fcm[\"participant_id\"].values\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Branch 1: XGB on Survey ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    learning_rate=0.05,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"logloss\",\n",
    "    n_jobs=-1,\n",
    "    verbosity=0,\n",
    "    random_state=42\n",
    ")\n",
    "clf_xgb = MultiOutputClassifier(xgb)\n",
    "clf_xgb.fit(X_survey, y_train)\n",
    "xgb_proba = clf_xgb.predict_proba(X_survey_test)\n",
    "branch1 = np.stack([p[:, 1] for p in xgb_proba], axis=1).astype(np.float32)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Branch 2: Ridge on fMRI PCA (0.90 & 0.95 ensemble) ‚îÄ\n",
    "ridge_preds = []\n",
    "for var in pca_vars:\n",
    "    pca = PCA(n_components=var, svd_solver=\"full\", random_state=42)\n",
    "    Xp_tr = pca.fit_transform(X_fmri)\n",
    "    Xp_te = pca.transform(X_fmri_test)\n",
    "\n",
    "    clf_ridge = MultiOutputClassifier(RidgeClassifier(alpha=1.0))\n",
    "    clf_ridge.fit(Xp_tr, y_train)\n",
    "    preds = clf_ridge.predict(Xp_te).astype(np.float32)\n",
    "    ridge_preds.append(preds)\n",
    "\n",
    "branch2 = np.mean(ridge_preds, axis=0)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 5) Combine & Threshold ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "final_soft = 0.5 * branch1 + 0.3 * branch2\n",
    "final_pred = np.zeros_like(final_soft, dtype=int)\n",
    "final_pred[:, 0] = (final_soft[:, 0] >= 0.5).astype(int)\n",
    "final_pred[:, 1] = (final_soft[:, 1] >= 0.5).astype(int)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 6) Save Submission ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "submission = pd.DataFrame({\n",
    "    \"participant_id\": test_ids,\n",
    "    \"ADHD_Outcome\": final_pred[:, 0],\n",
    "    \"Sex_F\": final_pred[:, 1]\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"‚úÖ submission.csv created: 50% XGB(survey) + 30% Ridge(fMRI PCA 0.90,0.95 & 0.99) ensemble\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkZCVHGgToOZ"
   },
   "source": [
    "### üôå Thank You!\n",
    "Thanks for reading! üíô If you have any suggestions, feel free to drop a comment ‚Äì I‚Äôm eager to learn and grow in this amazing community! üå± I‚Äôll be continuously updating this notebook with feature engineering, modeling, and detailed EDA observations for this competition.\n",
    "\n",
    "<div style=\"background-color: #FDEDEC; border-left: 8px solid #AF7AC5; padding: 20px; border-radius: 8px; font-size: 14px; color: #4A235A;\">\n",
    "  <h3 style=\"font-size: 20px; margin-bottom: 10px;\"><strong>üì¢ If you found this helpful, please upvote to support! üëç Happy coding and best of luck! üöÄüòä</strong></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-04T00:47:29.365281Z",
     "iopub.status.busy": "2025-04-04T00:47:29.364902Z",
     "iopub.status.idle": "2025-04-04T00:47:29.373257Z",
     "shell.execute_reply": "2025-04-04T00:47:29.371453Z",
     "shell.execute_reply.started": "2025-04-04T00:47:29.365255Z"
    },
    "id": "ayaS8tTnToOZ"
   },
   "source": [
    "<div style=\"background-color: #E8F8F5; border-left: 8px solid #1ABC9C; padding: 20px; border-radius: 8px; font-size: 14px; color: #000000;\">\n",
    "  <h3 style=\"font-size: 20px; margin-bottom: 10px;\">üì¨ <strong>Contact Information</strong></h3>\n",
    "  <hr>\n",
    "\n",
    "  <p>üìß <strong>Email:</strong> <a href=\"mailto:tarunpmishra2001@gmail.com\" style=\"color: #1ABC9C; text-decoration: none;\">tarunpmishra2001@gmail.com</a></p>\n",
    "\n",
    "  <p>üîó <strong>LinkedIn:</strong> <a href=\"https://www.linkedin.com/in/tarunpmishra/\" target=\"_blank\" style=\"color: #1ABC9C; text-decoration: none;\">linkedin.com/in/tarunpmishra</a></p>\n",
    "\n",
    "  <p>üåê <strong>Portfolio:</strong> <a href=\"https://tarundirector.github.io/tarunmishra.github.io/\" target=\"_blank\" style=\"color: #1ABC9C; text-decoration: none;\">tarundirector.github.io</a></p>\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11498594,
     "sourceId": 90566,
     "sourceType": "competition"
    },
    {
     "datasetId": 6843499,
     "sourceId": 11608956,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
