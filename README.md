# PROHI Dashboard Example

# [NeuroPredict]

_You can modify this README file with all the information that your team consider relevant for a technical audience who would like to understand your project or to run it in the future._

_Note that this file is written in **MarkDown** language. A reference is available here: <https://www.markdownguide.org/basic-syntax/>_

Include the name, logo and images refering to your project

![Your dashboard](./assets/example-image.jpg)

## Introduction

NeuroPredict is an interactive web dashboard to.... 

The problem detected was...

The proposed solution is valuable because...

## System description

### Structure 
NeuroPredict/
‚îú‚îÄ‚îÄ Dashboard.py                    # main page
‚îú‚îÄ‚îÄ pages/                         # Streamlit page
‚îÇ   ‚îú‚îÄ‚îÄ 1_üìä_Descriptive.py        # descriptive analysis (min. 5 questions)
‚îÇ   ‚îú‚îÄ‚îÄ 2_üîç_Diagnostic.py         # diagnostic analysisÔºàmin. 3 questionsÔºâ
‚îÇ   ‚îú‚îÄ‚îÄ 3_üéØ_Predictive.py         # predictive analysis
‚îÇ   ‚îú‚îÄ‚îÄ 4_üí°_Prescriptive.py       # SHAP explaintion
‚îÇ   ‚îî‚îÄ‚îÄ 5_‚ÑπÔ∏è_About.py              # About page
‚îú‚îÄ‚îÄ src/                           # core func module
‚îÇ   ‚îú‚îÄ‚îÄ data/                      # data processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader.py             # data loader
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessor.py       # data preprocess
‚îÇ   ‚îú‚îÄ‚îÄ analysis/                  # analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ descriptive.py        # descriptive func
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ diagnostic.py         # diagnostic func
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ statistical.py        # statisc func
‚îÇ   ‚îú‚îÄ‚îÄ models/                    # machine learning module
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_trainer.py      # model training
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predictor.py          # predictor interface
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluator.py          # model evaluation
‚îÇ   ‚îî‚îÄ‚îÄ visualization/            # visualization
‚îÇ       ‚îú‚îÄ‚îÄ plotly_charts.py      # Plotly
‚îÇ       ‚îî‚îÄ‚îÄ shap_plots.py         # SHAP
‚îú‚îÄ‚îÄ data/                         # data
‚îÇ   ‚îú‚îÄ‚îÄ raw/                      # raw data
‚îÇ   ‚îî‚îÄ‚îÄ processed/                # process data
‚îú‚îÄ‚îÄ models/                       # saved machine learning model
‚îÇ   ‚îî‚îÄ‚îÄ trained_models/          # trained modelÔºàpickleÔºâ
‚îú‚îÄ‚îÄ notebooks/                    # Jupyter
‚îÇ   ‚îú‚îÄ‚îÄ EDA & Modelling.ipynb    # Jupyter notebook
‚îú‚îÄ‚îÄ tests/                        # test doc
‚îú‚îÄ‚îÄ requirements.txt              # dependencies
‚îî‚îÄ‚îÄ README.md                     # docmentation

### Dependencies

Tested on Python 3.12.7 with the following packages:
  - Jupyter v1.1.1
  - Streamlit v1.46.1
  - Seaborn v0.13.2
  - Plotly v6.2.0
  - Scikit-Learn v1.7.0
  - shap v0.48.0

### Installation

Run the commands below in a terminal to configure the project and install the package dependencies for the first time.

If you are using Mac, you may need to follow install Xcode. Check the official Streamlit documentation [here](https://docs.streamlit.io/get-started/installation/command-line#prerequisites). 

1. Create the environment with `python -m venv env`
2. Activate the virtual environment for Python
   - `source env/bin/activate` [in Linux/Mac]
   - `.\env\Scripts\activate.bat` [in Windows command prompt]
   - `.\env\Scripts\Activate.ps1` [in Windows PowerShell]
3. Make sure that your terminal is in the environment (`env`) not in the global Python installation
4. Install required packages `pip install -r ./requirements.txt`
5. Check that everything is ok running `streamlit hello`

### Execution

To run the dashboard execute the following command:

```
> streamlit run Dashboard.py
# If the command above fails, use:
> python -m streamlit run Dashboard.py
```


### Creating pre-trained models for the web dashboadr 

‚ö†Ô∏è **NOTE:** In the predictive analytics tab, the web dashboard is looking for a pre-trained model in the folder `assets/`. The first time that you execute the application, it will show an error saying that such file does not exist. Therefore, you need to execute the notebook inside the folder `jupyter-notebook/` to create the pre-trained model.

This logic resembles the expected pipeline, where the jupyter notebooks are used to iterate the data modeling part until a satisfactory trained model is created, and the streamlit scripts are only in charge of rendering the user-facing interface to generate the prediction for new data. In practice, the data science pipeline is completely independent from the web dashboard, and both are connected via the pre-trained model. 

## Contributors

_Add the project's authors, contact information, and links to their websites or portfolios._
Laura Lemetti, Ding Xiao, Md Imran Mansur, Kaviya Palaniyappan, Songyue Xie
